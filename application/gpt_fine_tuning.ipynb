{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Create the JSONL dataset for fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091881\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/zhenyabudnyk/PycharmProjects/LyrAIX/Thesis/Data Labeling/lyrics_views2k.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "         Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0                       artist  \\\n0                   0             0           0                        JAY-Z   \n1                   1             1           1                        JAY-Z   \n2                   2             2           2                        JAY-Z   \n3                   3             3           3                        JAY-Z   \n4                   4             4           4                     Fabolous   \n...               ...           ...         ...                          ...   \n1091876       5282452       5282452     5282452  Genius English Translations   \n1091877       5282479       5282479     5282479                     Interpol   \n1091878       5282480       5282480     5282480                     Interpol   \n1091879       5282481       5282481     5282481                     Interpol   \n1091880       5282482       5282482     5282482                     Interpol   \n\n                                             title   tag  year   views  \\\n0                                       Can I Live   rap  1996  468624   \n1                                       Can I Live   rap  1996  468624   \n2                                       Can I Live   rap  1996  468624   \n3                                       Can I Live   rap  1996  468624   \n4                                Forgive Me Father   rap  2003    4743   \n...                                            ...   ...   ...     ...   \n1091876  Rammstein - Zick Zack English Translation  rock  2022    6568   \n1091877                                       Toni  rock  2022    3439   \n1091878                                       Toni  rock  2022    3439   \n1091879                                       Toni  rock  2022    3439   \n1091880                                       Toni  rock  2022    3439   \n\n           part                                             lyrics  \\\n0         Verse  While I'm watchin' every nigga watchin' me clo...   \n1        Chorus           Ge-ge-geyeahhh\\nCan I live?\\nCan I live?   \n2         Verse  My mind is infested with sick thoughts that ci...   \n3        Chorus  Can I live?\\nCan I live?\\nCan I live?\\nCan I l...   \n4          Hook  Forgive me father for I have sinned\\nBut look ...   \n...         ...                                                ...   \n1091876  Chorus  Snip-snip, snip-snip, cut that off\\nTick-tock,...   \n1091877   Verse  Flame down Pacific highway\\nStill in shape, my...   \n1091878  Chorus  I'd like to see them win\\nI like the inspirati...   \n1091879   Verse  The aim now is perfection always\\nThe aim now ...   \n1091880  Chorus  I'd like to see them win\\nI like the inspirati...   \n\n             explicitness                                            schemes  \\\n0        Explicit content  0-0-0-0-1-1-0-2-0-3-4-5-0-6-7-8-7-9-7-5-5-10-1...   \n1                  Normal                                              0-1-2   \n2                  Normal                  0-1-1-1-2-3-4-5-5-6-6-1-1-1-7-7-8   \n3                  Normal                                            0-1-2-3   \n4        Explicit content                                    0-0-0-0-1-0-0-0   \n...                   ...                                                ...   \n1091876            Normal                                              0-1-1   \n1091877            Normal                                            0-1-2-3   \n1091878            Normal                                        0-1-2-3-4-2   \n1091879  Explicit content                                            0-1-0-2   \n1091880            Normal                                        0-1-2-3-4-5   \n\n        Valence Arousal Dominance                   topic  \n0        Medium  Medium    Medium                 general  \n1          High    High      High  life and relationships  \n2        Medium  Medium      High                 general  \n3          High    High      High  life and relationships  \n4          High  Medium      High  life and relationships  \n...         ...     ...       ...                     ...  \n1091876  Medium  Medium       Low                 general  \n1091877     Low     Low       Low  life and relationships  \n1091878    High     Low      High     money and authority  \n1091879    High  Medium      High  life and relationships  \n1091880    High     Low      High     money and authority  \n\n[1091881 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.2</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>artist</th>\n      <th>title</th>\n      <th>tag</th>\n      <th>year</th>\n      <th>views</th>\n      <th>part</th>\n      <th>lyrics</th>\n      <th>explicitness</th>\n      <th>schemes</th>\n      <th>Valence</th>\n      <th>Arousal</th>\n      <th>Dominance</th>\n      <th>topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>JAY-Z</td>\n      <td>Can I Live</td>\n      <td>rap</td>\n      <td>1996</td>\n      <td>468624</td>\n      <td>Verse</td>\n      <td>While I'm watchin' every nigga watchin' me clo...</td>\n      <td>Explicit content</td>\n      <td>0-0-0-0-1-1-0-2-0-3-4-5-0-6-7-8-7-9-7-5-5-10-1...</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>general</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>JAY-Z</td>\n      <td>Can I Live</td>\n      <td>rap</td>\n      <td>1996</td>\n      <td>468624</td>\n      <td>Chorus</td>\n      <td>Ge-ge-geyeahhh\\nCan I live?\\nCan I live?</td>\n      <td>Normal</td>\n      <td>0-1-2</td>\n      <td>High</td>\n      <td>High</td>\n      <td>High</td>\n      <td>life and relationships</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>JAY-Z</td>\n      <td>Can I Live</td>\n      <td>rap</td>\n      <td>1996</td>\n      <td>468624</td>\n      <td>Verse</td>\n      <td>My mind is infested with sick thoughts that ci...</td>\n      <td>Normal</td>\n      <td>0-1-1-1-2-3-4-5-5-6-6-1-1-1-7-7-8</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>general</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>JAY-Z</td>\n      <td>Can I Live</td>\n      <td>rap</td>\n      <td>1996</td>\n      <td>468624</td>\n      <td>Chorus</td>\n      <td>Can I live?\\nCan I live?\\nCan I live?\\nCan I l...</td>\n      <td>Normal</td>\n      <td>0-1-2-3</td>\n      <td>High</td>\n      <td>High</td>\n      <td>High</td>\n      <td>life and relationships</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>Fabolous</td>\n      <td>Forgive Me Father</td>\n      <td>rap</td>\n      <td>2003</td>\n      <td>4743</td>\n      <td>Hook</td>\n      <td>Forgive me father for I have sinned\\nBut look ...</td>\n      <td>Explicit content</td>\n      <td>0-0-0-0-1-0-0-0</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>life and relationships</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1091876</th>\n      <td>5282452</td>\n      <td>5282452</td>\n      <td>5282452</td>\n      <td>Genius English Translations</td>\n      <td>Rammstein - Zick Zack English Translation</td>\n      <td>rock</td>\n      <td>2022</td>\n      <td>6568</td>\n      <td>Chorus</td>\n      <td>Snip-snip, snip-snip, cut that off\\nTick-tock,...</td>\n      <td>Normal</td>\n      <td>0-1-1</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>general</td>\n    </tr>\n    <tr>\n      <th>1091877</th>\n      <td>5282479</td>\n      <td>5282479</td>\n      <td>5282479</td>\n      <td>Interpol</td>\n      <td>Toni</td>\n      <td>rock</td>\n      <td>2022</td>\n      <td>3439</td>\n      <td>Verse</td>\n      <td>Flame down Pacific highway\\nStill in shape, my...</td>\n      <td>Normal</td>\n      <td>0-1-2-3</td>\n      <td>Low</td>\n      <td>Low</td>\n      <td>Low</td>\n      <td>life and relationships</td>\n    </tr>\n    <tr>\n      <th>1091878</th>\n      <td>5282480</td>\n      <td>5282480</td>\n      <td>5282480</td>\n      <td>Interpol</td>\n      <td>Toni</td>\n      <td>rock</td>\n      <td>2022</td>\n      <td>3439</td>\n      <td>Chorus</td>\n      <td>I'd like to see them win\\nI like the inspirati...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-2</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>money and authority</td>\n    </tr>\n    <tr>\n      <th>1091879</th>\n      <td>5282481</td>\n      <td>5282481</td>\n      <td>5282481</td>\n      <td>Interpol</td>\n      <td>Toni</td>\n      <td>rock</td>\n      <td>2022</td>\n      <td>3439</td>\n      <td>Verse</td>\n      <td>The aim now is perfection always\\nThe aim now ...</td>\n      <td>Explicit content</td>\n      <td>0-1-0-2</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>life and relationships</td>\n    </tr>\n    <tr>\n      <th>1091880</th>\n      <td>5282482</td>\n      <td>5282482</td>\n      <td>5282482</td>\n      <td>Interpol</td>\n      <td>Toni</td>\n      <td>rock</td>\n      <td>2022</td>\n      <td>3439</td>\n      <td>Chorus</td>\n      <td>I'd like to see them win\\nI like the inspirati...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>money and authority</td>\n    </tr>\n  </tbody>\n</table>\n<p>1091881 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df = df.drop(labels=[\"Unnamed: 0\", \"Unnamed: 0.1\", \"Unnamed: 0.2\"] ,axis=\"columns\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                              artist  \\\n0                              JAY-Z   \n1                              JAY-Z   \n2                              JAY-Z   \n3                              JAY-Z   \n4                           Fabolous   \n...                              ...   \n1091876  Genius English Translations   \n1091877                     Interpol   \n1091878                     Interpol   \n1091879                     Interpol   \n1091880                     Interpol   \n\n                                             title   tag  year   views  \\\n0                                       Can I Live   rap  1996  468624   \n1                                       Can I Live   rap  1996  468624   \n2                                       Can I Live   rap  1996  468624   \n3                                       Can I Live   rap  1996  468624   \n4                                Forgive Me Father   rap  2003    4743   \n...                                            ...   ...   ...     ...   \n1091876  Rammstein - Zick Zack English Translation  rock  2022    6568   \n1091877                                       Toni  rock  2022    3439   \n1091878                                       Toni  rock  2022    3439   \n1091879                                       Toni  rock  2022    3439   \n1091880                                       Toni  rock  2022    3439   \n\n           part                                             lyrics  \\\n0         Verse  While I'm watchin' every nigga watchin' me clo...   \n1        Chorus           Ge-ge-geyeahhh\\nCan I live?\\nCan I live?   \n2         Verse  My mind is infested with sick thoughts that ci...   \n3        Chorus  Can I live?\\nCan I live?\\nCan I live?\\nCan I l...   \n4          Hook  Forgive me father for I have sinned\\nBut look ...   \n...         ...                                                ...   \n1091876  Chorus  Snip-snip, snip-snip, cut that off\\nTick-tock,...   \n1091877   Verse  Flame down Pacific highway\\nStill in shape, my...   \n1091878  Chorus  I'd like to see them win\\nI like the inspirati...   \n1091879   Verse  The aim now is perfection always\\nThe aim now ...   \n1091880  Chorus  I'd like to see them win\\nI like the inspirati...   \n\n             explicitness                                            schemes  \\\n0        Explicit content  0-0-0-0-1-1-0-2-0-3-4-5-0-6-7-8-7-9-7-5-5-10-1...   \n1                  Normal                                              0-1-2   \n2                  Normal                  0-1-1-1-2-3-4-5-5-6-6-1-1-1-7-7-8   \n3                  Normal                                            0-1-2-3   \n4        Explicit content                                    0-0-0-0-1-0-0-0   \n...                   ...                                                ...   \n1091876            Normal                                              0-1-1   \n1091877            Normal                                            0-1-2-3   \n1091878            Normal                                        0-1-2-3-4-2   \n1091879  Explicit content                                            0-1-0-2   \n1091880            Normal                                        0-1-2-3-4-5   \n\n        Valence Arousal Dominance                   topic  \n0        Medium  Medium    Medium                 general  \n1          High    High      High  life and relationships  \n2        Medium  Medium      High                 general  \n3          High    High      High  life and relationships  \n4          High  Medium      High  life and relationships  \n...         ...     ...       ...                     ...  \n1091876  Medium  Medium       Low                 general  \n1091877     Low     Low       Low  life and relationships  \n1091878    High     Low      High     money and authority  \n1091879    High  Medium      High  life and relationships  \n1091880    High     Low      High     money and authority  \n\n[1091881 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist</th>\n      <th>title</th>\n      <th>tag</th>\n      <th>year</th>\n      <th>views</th>\n      <th>part</th>\n      <th>lyrics</th>\n      <th>explicitness</th>\n      <th>schemes</th>\n      <th>Valence</th>\n      <th>Arousal</th>\n      <th>Dominance</th>\n      <th>topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JAY-Z</td>\n      <td>Can I Live</td>\n      <td>rap</td>\n      <td>1996</td>\n      <td>468624</td>\n      <td>Verse</td>\n      <td>While I'm watchin' every nigga watchin' me clo...</td>\n      <td>Explicit content</td>\n      <td>0-0-0-0-1-1-0-2-0-3-4-5-0-6-7-8-7-9-7-5-5-10-1...</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>general</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>JAY-Z</td>\n      <td>Can I Live</td>\n      <td>rap</td>\n      <td>1996</td>\n      <td>468624</td>\n      <td>Chorus</td>\n      <td>Ge-ge-geyeahhh\\nCan I live?\\nCan I live?</td>\n      <td>Normal</td>\n      <td>0-1-2</td>\n      <td>High</td>\n      <td>High</td>\n      <td>High</td>\n      <td>life and relationships</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>JAY-Z</td>\n      <td>Can I Live</td>\n      <td>rap</td>\n      <td>1996</td>\n      <td>468624</td>\n      <td>Verse</td>\n      <td>My mind is infested with sick thoughts that ci...</td>\n      <td>Normal</td>\n      <td>0-1-1-1-2-3-4-5-5-6-6-1-1-1-7-7-8</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>general</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>JAY-Z</td>\n      <td>Can I Live</td>\n      <td>rap</td>\n      <td>1996</td>\n      <td>468624</td>\n      <td>Chorus</td>\n      <td>Can I live?\\nCan I live?\\nCan I live?\\nCan I l...</td>\n      <td>Normal</td>\n      <td>0-1-2-3</td>\n      <td>High</td>\n      <td>High</td>\n      <td>High</td>\n      <td>life and relationships</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fabolous</td>\n      <td>Forgive Me Father</td>\n      <td>rap</td>\n      <td>2003</td>\n      <td>4743</td>\n      <td>Hook</td>\n      <td>Forgive me father for I have sinned\\nBut look ...</td>\n      <td>Explicit content</td>\n      <td>0-0-0-0-1-0-0-0</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>life and relationships</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1091876</th>\n      <td>Genius English Translations</td>\n      <td>Rammstein - Zick Zack English Translation</td>\n      <td>rock</td>\n      <td>2022</td>\n      <td>6568</td>\n      <td>Chorus</td>\n      <td>Snip-snip, snip-snip, cut that off\\nTick-tock,...</td>\n      <td>Normal</td>\n      <td>0-1-1</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>general</td>\n    </tr>\n    <tr>\n      <th>1091877</th>\n      <td>Interpol</td>\n      <td>Toni</td>\n      <td>rock</td>\n      <td>2022</td>\n      <td>3439</td>\n      <td>Verse</td>\n      <td>Flame down Pacific highway\\nStill in shape, my...</td>\n      <td>Normal</td>\n      <td>0-1-2-3</td>\n      <td>Low</td>\n      <td>Low</td>\n      <td>Low</td>\n      <td>life and relationships</td>\n    </tr>\n    <tr>\n      <th>1091878</th>\n      <td>Interpol</td>\n      <td>Toni</td>\n      <td>rock</td>\n      <td>2022</td>\n      <td>3439</td>\n      <td>Chorus</td>\n      <td>I'd like to see them win\\nI like the inspirati...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-2</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>money and authority</td>\n    </tr>\n    <tr>\n      <th>1091879</th>\n      <td>Interpol</td>\n      <td>Toni</td>\n      <td>rock</td>\n      <td>2022</td>\n      <td>3439</td>\n      <td>Verse</td>\n      <td>The aim now is perfection always\\nThe aim now ...</td>\n      <td>Explicit content</td>\n      <td>0-1-0-2</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>life and relationships</td>\n    </tr>\n    <tr>\n      <th>1091880</th>\n      <td>Interpol</td>\n      <td>Toni</td>\n      <td>rock</td>\n      <td>2022</td>\n      <td>3439</td>\n      <td>Chorus</td>\n      <td>I'd like to see them win\\nI like the inspirati...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>money and authority</td>\n    </tr>\n  </tbody>\n</table>\n<p>1091881 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tiktoken'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtiktoken\u001B[39;00m \u001B[38;5;66;03m# for token counting\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m defaultdict\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tiktoken'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a Lyrics Writing Assistant, adept at creating song lyrics with specific guidelines. When given an artist's name, use it to capture the essence of their unique style, crafting lyrics that reflect their artistic identity. You will also receive characteristics of the song part (e.g., Chorus, Verse, Bridge, Hook), along with a rhyming scheme (e.g., 0-0-1-1, where the same numbers indicate rhyming lines).\n",
    "\n",
    "In addition, be mindful of the explicitness parameter: if the provided text is marked as 'explicit', your generated lyrics should also contain explicit content; if it's marked as 'non-explicit', ensure the lyrics are without explicit content. This aligns the lyrics with the intended audience and content sensitivity.\n",
    "\n",
    "You are also to incorporate emotional characteristics: valence (happiness level of the text, on a scale from low to high), arousal (activity level of the mood, from low to high), and dominance (assertiveness of the message, from low to high). Generalized topics for the lyrics will be provided, which should guide the theme or subject matter.\n",
    "\n",
    "Your primary task is to generate new, authentic lyrics that align with these defined characteristics, focusing on creativity and adherence to the guidelines. The goal is to produce lyrics that resonate with the artist's style and the specified emotional and thematic parameters, ensuring relevance and originality in your lyrical composition.\"\"\"\n",
    "with open('fine_tuning.jsonl', 'w') as file:\n",
    "    for i, row in df.iterrows():\n",
    "        data = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f'Generate a new {row[\"part\"]} of a song lyrics in the style of {row[\"artist\"]}. The valence level should be'\n",
    "                                    f' {row[\"Valence\"]}, arousal level should be {row[\"Arousal\"]} and dominance level should be {row[\"Dominance\"]}'\n",
    "                                    f'. The generated lyrics should have {\"explicit content\" if row[\"explicitness\"] else \"non-explicit content\"}. The approximate rhyming scheme should be {row[\"schemes\"]}.'\n",
    "                                    f'The topic of the lyrical text should be {row[\"topic\"]}.'},\n",
    "        {\"role\": \"assistant\", \"content\":  row[\"lyrics\"]}\n",
    "    ]\n",
    "}\n",
    "        json_str = json.dumps(data)\n",
    "        file.write(json_str + '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Check the fine-tuning data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 1091881\n",
      "First example:\n",
      "{'role': 'system', 'content': \"You are a Lyrics Writing Assistant, adept at creating song lyrics with specific guidelines. When given an artist's name, use it to capture the essence of their unique style, crafting lyrics that reflect their artistic identity. You will also receive characteristics of the song part (e.g., Chorus, Verse, Bridge, Hook), along with a rhyming scheme (e.g., 0-0-1-1, where the same numbers indicate rhyming lines).\\n\\nIn addition, be mindful of the explicitness parameter: if the provided text is marked as 'Explicit', your generated lyrics should also contain explicit content; if it's marked as 'Normal', ensure the lyrics are without explicit content. This aligns the lyrics with the intended audience and content sensitivity.\\n\\nYou are also to incorporate emotional characteristics: valence (happiness level of the text, on a scale from low to high), arousal (activity level of the mood, from low to high), and dominance (assertiveness of the message, from low to high). Generalized topics for the lyrics will be provided, which should guide the theme or subject matter.\\n\\nYour primary task is to generate new, authentic lyrics that align with these defined characteristics, focusing on creativity and adherence to the guidelines. The goal is to produce lyrics that resonate with the artist's style and the specified emotional and thematic parameters, ensuring relevance and originality in your lyrical composition.\"}\n",
      "{'role': 'user', 'content': 'Generate a new Verse of a song lyrics in the style of JAY-Z. The valence level should be Medium, arousal level should be Medium and dominance level should be Medium. The content should be Explicit content. The approximate rhyming scheme should be 0-0-0-0-1-1-0-2-0-3-4-5-0-6-7-8-7-9-7-5-5-10-10-7-7-5-11-12-13-1-14-15-5.The topic of the lyrical text should be general.'}\n",
      "{'role': 'assistant', 'content': 'While I\\'m watchin\\' every nigga watchin\\' me closely\\nMy shit is butter for the bread, they wanna toast me\\nI keep my head, both of them, where they supposed to be\\nHoes\\'ll get you sidetracked, then clapped from close feet\\nI don\\'t sleep, I\\'m tired, I feel wired like codeine, these days\\nA brother gotta admire me from four fiends away\\nMy pain, wish it was quick to see\\nFrom sellin\\' \\'caine \\'til brains was fried to a fricassee\\nCan\\'t lie, at the time it never bothered me\\nAt the bar, gettin\\' my thug on properly\\nMy squad and me lack of respect for authority\\nLaughin\\' hard, happy to be escapin\\' poverty, however brief\\nI know this game got valleys and peaks\\nExpectation for dips, for precipitation we stack chips, hardly\\nThe youth I used to be, soon to see a mill\\'in\\nNo more Big Willie, my game has grown\\nPrefer you call me William\\nIllin\\' for revenues, Rayful Edmond-like\\nChannel 7 News, round seven jewels, head dead in the mic\\nForgettin\\' all I ever knew, convenient amnesia\\n\"I suggest you call my lawyer, I know the procedure.\"\\nLock my body, can\\'t trap my mind\\nEasily explain why we adapt to crime\\nI\\'d rather die enormous than live dormant, that\\'s how we on it\\nLive at the main event, I bet a trip to Maui on it\\nPresidential suites my residential for the weekend\\nConfidentially speakin\\' in codes since I sense you peekin\\'\\nThe NSX rental, don\\'t be fooled, my game is mental\\nWe both out of town, dog, what you tryin\\' to get into?\\nViva Las Vegas, see ya later at the crap tables\\nMeet me by the one that starts a G up\\nThis way no Fraud Willies present gamblin\\' they re-up\\nAnd we can have a pleasant time, sippin\\' margaritas'}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/zhenyabudnyk/PycharmProjects/LyrAIX/application/fine_tuning.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "\n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "\n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "\n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
