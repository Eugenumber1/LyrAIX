{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is dedicated to the exploration of the Lyrics dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 40000\n",
    "lyrics = pd.read_csv('../song_lyrics.csv', nrows=n_rows)\n",
    "# lyrics[:10, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lyrics.iloc[:10, 2:8]\n",
    "# print(lyrics.iat[9,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>language_cld3</th>\n",
       "      <th>language_ft</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>173166</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Opera Steve\"}</td>\n",
       "      <td>[Chorus: Opera Steve &amp; Cam'ron]\\nKilla Cam, Ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>468624</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fabolous</td>\n",
       "      <td>2003</td>\n",
       "      <td>4743</td>\n",
       "      <td>{}</td>\n",
       "      <td>Maybe cause I'm eatin\\nAnd these bastards fien...</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>144404</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}</td>\n",
       "      <td>[Produced by Kanye West and Brian Miller]\\n\\n[...</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>78271</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lollipop Remix</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2008</td>\n",
       "      <td>580832</td>\n",
       "      <td>{\"Kanye West\",\"Static Major\"}</td>\n",
       "      <td>[Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...</td>\n",
       "      <td>7</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Im Not You</td>\n",
       "      <td>rap</td>\n",
       "      <td>Clipse</td>\n",
       "      <td>2002</td>\n",
       "      <td>28645</td>\n",
       "      <td>{Jadakiss,\"Styles P\",\"Roscoe P. Coldchain\"}</td>\n",
       "      <td>[Intro: Pusha T]\\nNo, no, no!\\nI told you, I l...</td>\n",
       "      <td>8</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Family Ties</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>41960</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Lady Wray\"}</td>\n",
       "      <td>[Verse 1: Cam'ron]\\nKilla, Dipset\\nMan I spit ...</td>\n",
       "      <td>9</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rockin and Rollin</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>1998</td>\n",
       "      <td>6399</td>\n",
       "      <td>{\"Cam\\\\'ron\"}</td>\n",
       "      <td>[Verse 1]\\nAy yo you wonder who I are\\nI guzzl...</td>\n",
       "      <td>10</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lord You Know</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>11882</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Juelz Santana\",Jaheim}</td>\n",
       "      <td>[Chorus: Jaheim]\\nNow Lord you know, just how ...</td>\n",
       "      <td>11</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  tag     artist  year   views  \\\n",
       "0          Killa Cam  rap    Cam'ron  2004  173166   \n",
       "1         Can I Live  rap      JAY-Z  1996  468624   \n",
       "2  Forgive Me Father  rap   Fabolous  2003    4743   \n",
       "3       Down and Out  rap    Cam'ron  2004  144404   \n",
       "4             Fly In  rap  Lil Wayne  2005   78271   \n",
       "5     Lollipop Remix  rap  Lil Wayne  2008  580832   \n",
       "6         Im Not You  rap     Clipse  2002   28645   \n",
       "7        Family Ties  rap    Cam'ron  2004   41960   \n",
       "8  Rockin and Rollin  rap    Cam'ron  1998    6399   \n",
       "9      Lord You Know  rap    Cam'ron  2004   11882   \n",
       "\n",
       "                                       features  \\\n",
       "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
       "1                                            {}   \n",
       "2                                            {}   \n",
       "3  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
       "4                                            {}   \n",
       "5                 {\"Kanye West\",\"Static Major\"}   \n",
       "6   {Jadakiss,\"Styles P\",\"Roscoe P. Coldchain\"}   \n",
       "7                     {\"Cam\\\\'ron\",\"Lady Wray\"}   \n",
       "8                                 {\"Cam\\\\'ron\"}   \n",
       "9          {\"Cam\\\\'ron\",\"Juelz Santana\",Jaheim}   \n",
       "\n",
       "                                              lyrics  id language_cld3  \\\n",
       "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1            en   \n",
       "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3            en   \n",
       "2  Maybe cause I'm eatin\\nAnd these bastards fien...   4            en   \n",
       "3  [Produced by Kanye West and Brian Miller]\\n\\n[...   5            en   \n",
       "4  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6            en   \n",
       "5  [Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...   7            en   \n",
       "6  [Intro: Pusha T]\\nNo, no, no!\\nI told you, I l...   8            en   \n",
       "7  [Verse 1: Cam'ron]\\nKilla, Dipset\\nMan I spit ...   9            en   \n",
       "8  [Verse 1]\\nAy yo you wonder who I are\\nI guzzl...  10            en   \n",
       "9  [Chorus: Jaheim]\\nNow Lord you know, just how ...  11            en   \n",
       "\n",
       "  language_ft language  \n",
       "0          en       en  \n",
       "1          en       en  \n",
       "2          en       en  \n",
       "3          en       en  \n",
       "4          en       en  \n",
       "5          en       en  \n",
       "6          en       en  \n",
       "7          en       en  \n",
       "8          en       en  \n",
       "9          en       en  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics.iloc[:10 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove brackets\n",
    "Here we remove the brackets from the lyrics, that they can be used by the classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(song):\n",
    "    output_text = re.sub(r'\\[\\s*.*?\\s*\\]\\n', '', song)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the content of the cell\n",
    "import string\n",
    "cell_content = lyrics.iat[5000,6]  # Replace with the appropriate row and column labels\n",
    "# print(str(cell_content))\n",
    "# Specify the file path and name for the text file\n",
    "file_path = '../files/lyrics.txt'\n",
    "\n",
    "# Write the cell content to the text file\n",
    "with open(file_path, 'w') as file:\n",
    "    lines = str(cell_content).splitlines()\n",
    "    for line in lines:\n",
    "        if line.strip():  # Check if the line is non-blank\n",
    "            # print(line)\n",
    "            last_two_words = re.findall(r'\\b(\\w+\\W*\\w+)\\W*$', line)[-1]\n",
    "            last_two_words = re.sub(r'\\d', '', last_two_words)  # Remove numbers\n",
    "            last_two_words = last_two_words.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "            file.write(last_two_words + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we remove the lyrics of the other languages that are not english, we drop each row which contains such\n",
    "and we reindex the table afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in lyrics.iterrows():\n",
    "    if row['language'] != 'en':\n",
    "        lyrics.drop(i, inplace=True)\n",
    "        # print('Hey it is not an english lyrics!')\n",
    "    else:\n",
    "        cleaned = preprocess(row['lyrics'])\n",
    "        lyrics.at[i, 'lyrics'] = cleaned\n",
    "\n",
    "\n",
    "lyrics.reset_index(drop=True, inplace=True)\n",
    "# lyrics.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39648, 11)\n"
     ]
    }
   ],
   "source": [
    "print(lyrics.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhyme extraction\n",
    "What could be the desired marked formats?\n",
    "1. Most frequent scheme - ABAB, ABBA (underfitting)\n",
    "2. The exact words that are being rhymed?\n",
    "3. The whole rhyming scheme of the song - ABABCDDC-FFFF-ABABCDCD-FFFF-FFFF (overfitting)\n",
    "4. Multisyllable rhymes - (AB)(AB)(CB)(CB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path and name\n",
    "file_path = '../cmudict.dict'\n",
    "\n",
    "# Create an empty dictionary to store the word-phoneme mappings\n",
    "word_phoneme_dict = {}\n",
    "\n",
    "encodings = ['utf-8', 'latin-1', 'utf-16', 'cp1252']\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    #print(line)\n",
    "                    split = line.split()\n",
    "                    word_phoneme_dict[split[0]] = ' '.join(split[1:])\n",
    "            # break\n",
    "    except UnicodeDecodeError:\n",
    "        print('Error')\n",
    "\n",
    "# Print the dictionary\n",
    "#print(word_phoneme_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EY1 N T\n",
      "135167\n"
     ]
    }
   ],
   "source": [
    "print(word_phoneme_dict.get(\"ain't\"))\n",
    "print(len(word_phoneme_dict))\n",
    "# print(word_phoneme_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Memory: 6.03 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get the current available memory in bytes\n",
    "available_memory = psutil.virtual_memory().available\n",
    "\n",
    "# Convert bytes to human-readable format\n",
    "available_memory_gb = available_memory / (1024 ** 3)  # Convert bytes to gigabytes\n",
    "\n",
    "# Print the available memory\n",
    "print(f\"Available Memory: {available_memory_gb:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea\n",
    "We take each row, take the lyrics from it, split the lyrics by whitespace, remove the special characters, maybe remove some stuff that is in the round brackets (aka low voice stuff), then we take only the last two words in each line, and we annotate them with corresponding phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_for_rhymes(lyric):\n",
    "    lyric = re.sub(r'[^A-Za-z0-9\\s]', '', lyric) # remove special chars\n",
    "    lyric = lyric.lower()\n",
    "    lyric = lyric.split('\\n') # split by new lines\n",
    "    lyric = list(filter(lambda line: line != '', lyric)) # delete an empty line\n",
    "    for i, line in enumerate(lyric):\n",
    "        line = line.split()\n",
    "        if len(line) >= 2:\n",
    "            lyric[i] = line[-2:] # take the last two words of each line\n",
    "        else:\n",
    "            lyric[i] = line\n",
    "\n",
    "    return lyric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column in the dataset and apply the cleaning function to it\n",
    "lyrics['end words'] = lyrics['lyrics'].apply(clean_for_rhymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cam', 'cam'], ['killa', 'cam'], ['cam', 'cam'], ['cam', 'cam'], ['killa', 'cam'], ['killa', 'killa'], ['bases', 'loaded'], ['cam', 'uhhuh'], ['on', 'third'], ['at', 'bat'], ['killa', 'cam'], ['the', 'world'], ['cam', 'cam'], ['killa', 'cam'], ['cam', 'hahahaha'], ['cam', 'cam'], ['killa', 'cam'], ['shit', 'clap'], ['cam', 'cam'], ['killa', 'cam'], ['cam', 'cam'], ['cam', 'cam'], ['killa', 'killa'], ['cam', 'killa'], ['what', 'up'], ['since', 'kumbaya'], ['my', 'lord'], ['on', 'board'], ['tutor', 'me'], ['to', 'me'], ['or', 'dime'], ['hammer', 'time'], ['on', 'nines'], ['camll', 'shine'], ['red', 'red'], ['em', 'lemonheads'], ['like', 'winnipeg'], ['with', 'fred'], ['on', 'scrappy'], ['at', 'me'], ['laffy', 'taffy'], ['killa', 'cam'], ['cam', 'sing'], ['killa', 'cam'], ['me', 'clap'], ['killa', 'cam'], ['cam', 'cam'], ['cam', 'sing'], ['me', 'clap'], ['killa', 'cam'], ['cam', 'sing'], ['killa', 'cam'], ['its', 'me'], ['killa', 'cam'], ['cam', 'cam'], ['cam', 'clap'], ['about', 'this'], ['killa', 'killa'], ['as', 'fuck'], ['pitchin', 'up'], ['it', 'up'], ['up', 'killa'], ['towaway', 'zone'], ['dont', 'care'], ['homes', 'killa'], ['to', 'problems'], ['get', 'pardons'], ['we', 'bang'], ['pootie', 'tang'], ['stoolie', 'sings'], ['toolie', 'sing'], ['bang', 'bang'], ['movie', 'ring'], ['jewelry', 'bling'], ['he', 'bring'], ['he', 'ring'], ['cuties', 'cling'], ['the', 'river'], ['sushi', 'king'], ['ya', 'fresh'], ['ya', 'flesh'], ['please', 'confess'], ['best', 'killa'], ['cam', 'sing'], ['cam', 'clap'], ['cam', 'yes'], ['me', 'sing'], ['killa', 'cam'], ['cam', 'sing'], ['killa', 'cam'], ['sir', 'uhh'], ['killa', 'cam'], ['sing', 'clap'], ['killa', 'cam'], ['its', 'me'], ['sing', 'clap'], ['cam', 'cam'], ['killa', 'cam'], ['shit', 'listen'], ['cam', 'killa'], ['killa', 'yo'], ['is', 'this'], ['a', 'chick'], ['or', 'piff'], ['sniff', 'everything'], ['my', 'drift'], ['shit', 'millions'], ['roaster', 'bitch'], ['ya', 'bitch'], ['usually', 'ends'], ['groupie', 'friends'], ['coochie', 'cleansed'], ['pucci', 'men'], ['escada', 'prada'], ['uzi', 'lens'], ['birdseye', 'view'], ['flip', 'birds'], ['i', 'flew'], ['i', 'grew'], ['on', 'stoops'], ['in', 'coupes'], ['killa', 'uhh'], ['killa', 'cam'], ['cam', 'cam'], ['killa', 'cam'], ['cam', 'cam'], ['killa', 'cam'], ['cam', 'cam'], ['killa', 'cam'], ['cam', 'killa'], ['killa', 'cam'], ['cam', 'cam'], ['killa', 'cam'], ['cam', 'cam'], ['killa', 'cam'], ['cam', 'cam'], ['killa', 'cam'], ['cam', 'killa']]\n",
      "[['yeah', 'rocafella'], ['you', 'know'], ['of', 'hopelessness'], ['a', 'desperation'], ['become', 'addicted'], ['to', 'servin'], ['to', 'lose'], ['lives', 'right'], ['the', 'table'], ['me', 'closely'], ['toast', 'me'], ['to', 'be'], ['close', 'feet'], ['these', 'days'], ['fiends', 'away'], ['to', 'see'], ['a', 'fricassee'], ['bothered', 'me'], ['on', 'properly'], ['for', 'authority'], ['however', 'brief'], ['and', 'peaks'], ['chips', 'hardly'], ['a', 'millin'], ['has', 'grown'], ['me', 'william'], ['rayful', 'edmondlike'], ['the', 'mic'], ['convenient', 'amnesia'], ['the', 'procedure'], ['my', 'mind'], ['to', 'crime'], ['on', 'it'], ['on', 'it'], ['the', 'weekend'], ['you', 'peekin'], ['is', 'mental'], ['get', 'into'], ['crap', 'tables'], ['g', 'up'], ['they', 'reup'], ['sippin', 'margaritas'], ['gegegeyeahhh'], ['i', 'live'], ['i', 'live'], ['that', 'circle'], ['hurt', 'you'], ['in', 'unity'], ['got', 'immunity'], ['manifest', 'it'], ['rolexd', 'it'], ['you', 'should'], ['a', 'nation'], ['said', 'patient'], ['to', 'it'], ['through', 'this'], ['money', 'foolish'], ['for', 'intruders'], ['a', 'buddhist'], ['gettin', 'cream'], ['gets', 'tedious'], ['stressed', 'right'], ['i', 'live'], ['i', 'live'], ['i', 'live'], ['i', 'live']]\n",
      "[['im', 'eatin'], ['they', 'grub'], ['these', 'scrubs'], ['on', 'dubs'], ['they', 'hubs'], ['to', 'rub'], ['the', 'tub'], ['the', 'club'], ['my', 'bub'], ['dick', 'her'], ['a', 'sticker'], ['up', 'sicker'], ['to', 'flicker'], ['it', 'quicker'], ['some', 'liquor'], ['on', 'niggas'], ['a', 'while'], ['snicker', 'yeyeyea'], ['have', 'sinned'], ['i', 'spend'], ['im', 'in'], ['ive', 'been'], ['those', 'brims'], ['im', 'in'], ['theres', 'been'], ['it', 'again'], ['with', 'me'], ['lee', 'titty'], ['wit', 'me'], ['for', 'threefifty'], ['with', 'me'], ['p', 'diddy'], ['with', 'me'], ['these', 'bitties'], ['gunll', 'jam'], ['gonna', 'blam'], ['opie', 'cunningham'], ['uncle', 'sam'], ['hunned', 'grams'], ['summer', 'jam'], ['better', 'sense'], ['settlements', 'nigga'], ['by', 'ya'], ['a', 'pacifier'], ['last', 'supplier'], ['some', 'fire'], ['is', 'regular'], ['like', 'editors'], ['beggin', 'ya'], ['in', 'predator'], ['fiends', 'now'], ['between', 'rounds'], ['want', 'beef'], ['front', 'teeth'], ['small', 'cup'], ['the', 'cris'], ['of', 'piss'], ['catch', 'up']]\n",
      "[['ugh', 'killa'], ['baby'], ['flow', 'huh'], ['it', 'up'], ['ugh', 'ugh'], ['this', 'year'], ['ye', 'cmon'], ['never', 'hated'], ['i', 'hesitated'], ['block', 'away'], ['osaka', 'bay'], ['suckers', 'place'], ['her', 'face'], ['her', 'taste'], ['the', 'taste'], ['im', 'cooking'], ['the', 'juxes'], ['from', 'brooklyn'], ['just', 'looking'], ['the', 'pudding'], ['hardtangled', 'grammar'], ['starspangled', 'banner'], ['manning', 'tanners'], ['hes', 'back'], ['down', 'down'], ['not', 'out'], ['no', 'no'], ['juiciest', 'ooooh'], ['down', 'down'], ['not', 'out'], ['no', 'no'], ['mine', 'oooh'], ['simon', 'says'], ['your', 'head'], ['and', 'red'], ['dead', 'doggy'], ['thats', 'necessary'], ['pet', 'sematary'], ['animal', 'activists'], ['with', 'savages'], ['gather', 'loot'], ['rather', 'shoot'], ['battered', 'boots'], ['a', 'parachute'], ['my', 'flip'], ['the', 'shit'], ['i', 'get'], ['cris', 'oww'], ['down', 'down'], ['not', 'out'], ['no', 'no'], ['juiciest', 'ooooh'], ['down', 'down'], ['not', 'out'], ['no', 'no'], ['mine', 'oooh'], ['yo', 'ayo'], ['pure', 'thick'], ['youre', 'it'], ['by', 'drivethru'], ['quarters', 'skyblue'], ['blue', '52'], ['how', 'you'], ['fly', 'too'], ['fly', 'too'], ['to', 'bake'], ['the', 'weight'], ['the', 'jakes'], ['your', 'wake'], ['a', 'lake'], ['to', 'escape'], ['the', 'four'], ['you', 'so'], ['ugh', 'killa'], ['down', 'down'], ['not', 'out'], ['no', 'no'], ['juiciest', 'ooooh'], ['down', 'down'], ['not', 'out'], ['no', 'no'], ['mine', 'oooh'], ['mine', 'killa'], ['know', 'harlem'], ['st', 'louis'], ['of', 'course'], ['at', 'me'], ['wild', 'hundreds'], ['is', 'ohio'], ['your', 'boy'], ['i', 'do'], ['cleveland', 'cincinnati']]\n",
      "[['ask', 'me'], ['young', 'boy'], ['time', 'around'], ['come', 'back'], ['told', 'em'], ['like', '32'], ['like', '33'], ['hit', 'me'], ['thats', 'nothing'], ['ii', 'people'], ['ii', 'people'], ['hey'], ['the', 'daughter'], ['the', 'father'], ['mildew', 'hater'], ['glaciers', 'gracias'], ['its', 'obvious'], ['is', 'atheist'], ['angel', 'dust'], ['your', 'honor'], ['your', 'honor'], ['with', 'power'], ['get', 'hotter'], ['the', 'counter'], ['the', 'cupboard'], ['the', 'bubbles'], ['my', 'dope'], ['aint', 'soap'], ['aint', 'broke'], ['go', 'no'], ['is', 'blue'], ['blue', 'jewelry'], ['the', 'money'], ['tummy', 'oh'], ['in', 'public'], ['warning', 'nothing'], ['or', 'nothing'], ['nigga', 'lunch'], ['nigga', 'fronts'], ['we', 'want'], ['me', 'here'], ['be', 'here'], ['me', 'here'], ['be', 'here'], ['so', 'fundamental'], ['the', 'windows'], ['it', 'home'], ['every', 'song'], ['no', 'bark'], ['old', 'shark'], ['bout', 'stunna'], ['your', 'ho'], ['the', 'prince'], ['like', 'that']]\n",
      "[['haha'], ['uhhuh'], ['mula', 'baby'], ['the', 'wrapper'], ['remix', 'baby'], ['dolly', 'parton'], ['the', 'top'], ['the', 'spot'], ['to', 'shop'], ['so', 'freeze'], ['cho', 'cheese'], ['to', 'lay'], ['to', 'wait'], ['gon', 'melt'], ['everybody', 'else'], ['for', 'myself'], ['the', 'belt'], ['get', 'melt'], ['dont', 'melt'], ['wont', 'help'], ['oh', 'oh'], ['of', 'town'], ['of', 'bounds'], ['baby', 'girl'], ['the', 'world'], ['lollipop'], ['the', 'world'], ['a', 'lollipop'], ['world', 'world'], ['a', 'lollipop'], ['thug', 'thug'], ['the', 'club'], ['shawty', 'wanna'], ['shawty', 'wanna'], ['shawty', 'wanna'], ['like', 'that'], ['like', 'that'], ['that', 'haha'], ['lumps', 'lumps'], ['the', 'wrapper'], ['the', 'rapper'], ['pornoflicking', 'actor'], ['that', 'rapture'], ['hewlett', 'packard'], ['a', 'snacker'], ['fudge', 'tastes'], ['bloods', 'sakesoowoo'], ['do', 'dididissipate'], ['to', 'participate'], ['the', 'chain'], ['my', 'chain'], ['is', 'bang'], ['your', 'poison'], ['mr', 'ointment'], ['mr', 'icantmakeanappointment'], ['enjoy', 'itremix'], ['thug', 'yeah'], ['club', 'yeah'], ['shawty', 'wanna'], ['shawty', 'wanna'], ['shawty', 'wanna'], ['like', 'that'], ['like', 'that'], ['that', 'haha'], ['lumps', 'lumps'], ['odd', 'cookie'], ['a', 'building'], ['the', 'shit'], ['i', 'sit'], ['like', 'hideandgo'], ['miney', 'mo'], ['cdthing', 'tapedeck'], ['great', 'sex'], ['a', 'latex'], ['late', 'text'], ['it', 'up'], ['the', 'wrapper'], ['a', 'thug'], ['club', 'club'], ['wanna', 'hump'], ['to', 'touch'], ['rerereremix', 'baby'], ['lollipop', 'lollipop'], ['lollipop', 'llollipop'], ['lollipop', 'lollipop'], ['lollipop', 'lollipop']]\n",
      "[['no', 'no'], ['this', 'shit'], ['and', 'tappin'], ['and', 'shit'], ['not', 'me'], ['you', 'rapper'], ['you', 'pusha'], ['the', 'stitches'], ['the', 'malicious'], ['the', 'sniffles'], ['the', 'itches'], ['the', 'vaseline'], ['thats', 'green'], ['thats', 'green'], ['the', 'lean'], ['rented', 'camrys'], ['of', 'shit'], ['dont', 'crash'], ['of', 'slab'], ['air', 'bags'], ['brothers', 'skits'], ['pop', 'out'], ['drop', 'out'], ['damn', 'lie'], ['grams', 'hide'], ['need', 'it'], ['believe', 'it'], ['i', 'smile'], ['ai', 'style'], ['so', 'what'], ['know', 'what'], ['good', 'job'], ['built', 'me'], ['another', 'brother'], ['a', 'motherfucker'], ['got', 'money'], ['act', 'funny'], ['dont', 'discriminate'], ['will', 'eliminate'], ['block', 'reps'], ['hot', 'sets'], ['killer', 'how'], ['killer', 'clowns'], ['my', 'heart'], ['my', 'man'], ['he', 'can'], ['point', 'blank'], ['nigga', 'stankin'], ['in', 'it'], ['to', 'blink'], ['shocked', 'em'], ['rocked', 'em'], ['made', 'you'], ['that', 'pretends'], ['through', 'men'], ['through', 'men'], ['with', 'death'], ['ya', 'chest'], ['to', 'rest'], ['to', 'rep'], ['i', 'step'], ['slept', 'on'], ['stepped', 'on'], ['rep', 'wrong'], ['set', 'gone'], ['em', 'poor'], ['than', 'yours'], ['move', 'backwards'], ['jerk', 'you'], ['hood', 'and'], ['ocean', 'floor'], ['a', 'bull'], ['i', 'pull'], ['come', 'on'], ['coke', 'uhuh'], ['common', 'bond'], ['arms', 'no'], ['no', 'end'], ['kin', 'uhhuh'], ['will', 'supply'], ['time', 'cry'], ['need', 'this'], ['their', 'jesus'], ['the', 'streets'], ['so', 'sorry'], ['didnt', 'quit'], ['aint', 'shit'], ['the', 'fact'], ['after', 'that']]\n",
      "[['killa', 'dipset'], ['pimps', 'collide'], ['the', 'ride'], ['pimp', 'stance'], ['shrimp', 'scamp'], ['you', 'gggay'], ['a', 'bouquet'], ['you', 'stayed'], ['you', 'stayed'], ['fit', 'cap'], ['commit', 'that'], ['time', 'share'], ['dimes', 'here'], ['more', 'authority'], ['for', 'me'], ['the', 'orgy'], ['applaud', 'me'], ['stand', 'by'], ['drums', 'cry'], ['dipset', 'dipset'], ['push', 'us'], ['family', 'ties'], ['dipset', 'dipset'], ['killa', 'uhh'], ['the', 'copride'], ['cop', 'rides'], ['hot', 'thighs'], ['shes', 'cockeyed'], ['bacon', 'rolls'], ['makin', 'dough'], ['jamaican', 'clothes'], ['we', 'go'], ['he', 'know'], ['baby', 'pinocchio'], ['blue', 'mittens'], ['you', 'pitchin'], ['kitchenswhos', 'bitchin'], ['the', 'fuschnickens'], ['a', 'hoe'], ['to', 'babymother'], ['a', 'ladylover'], ['clap', 'her'], ['nut', 'cracker'], ['rell', 'home'], ['cell', 'phone'], ['family', 'rise'], ['ties', 'killa'], ['stand', 'by'], ['drums', 'cry'], ['dipset', 'dipset'], ['push', 'us'], ['family', 'ties'], ['dipset', 'dipset'], ['just', 'faint'], ['latterday', 'saints'], ['in', 'paint'], ['back', 'abracadabra'], ['all', 'comfortable'], ['theodore', 'huxtable'], ['a', 'doctor'], ['locker', 'and'], ['the', 'rosaries'], ['of', 'd'], ['of', 'd'], ['to', 'me'], ['to', 'me'], ['like', 'me'], ['for', 'me'], ['is', 'me'], ['stand', 'by'], ['drums', 'cry'], ['dipset', 'dipset'], ['push', 'us'], ['family', 'ties'], ['dipset', 'dipset']]\n",
      "[['i', 'are'], ['the', 'bar'], ['double', 'r'], ['rocky', 'rolly'], ['hockey', 'goalie'], ['eating', 'guacamole'], ['did', 'without'], ['it', 'out'], ['it', 'out'], ['it', 'out'], ['long', 'gone'], ['hong', 'kong'], ['thong', 'on'], ['don', 'juan'], ['drinking', 'chandon'], ['chron', 'ma'], ['girl', 'uhhuh'], ['car', 'up'], ['long', 'ride'], ['wrong', 'side'], ['im', 'sorry'], ['the', 'ferrari'], ['like', 'bacardi'], ['with', 'safari'], ['da', 'di'], ['to', 'party'], ['with', 'somebody'], ['and', 'rollin'], ['and', 'smokin'], ['we', 'chokin'], ['and', 'hopin'], ['spoke', 'in'], ['youre', 'open'], ['new', '5'], ['be', 'live'], ['actor', 'really'], ['acting', 'silly'], ['did', 'he'], ['baddest', 'biddies'], ['is', 'pretty'], ['magic', 'city'], ['the', 'coco'], ['im', 'loco'], ['the', 'popo'], ['stroke', 'hoes'], ['for', 'homos'], ['doing', 'promos'], ['the', 'soso'], ['we', 'at'], ['to', 'act'], ['be', 'strapped'], ['of', 'riley'], ['or', 'pat'], ['the', 'cash'], ['with', 'that'], ['to', 'bet'], ['be', 'cracked'], ['little', 'girlfriend'], ['the', 'bat'], ['chevy', 'tonight'], ['be', 'back'], ['night', 'stand'], ['the', 'sack'], ['miss', 'it'], ['kiss', 'it'], ['come', 'on'], ['a', 'beach'], ['a', 'tree'], ['a', 'g'], ['the', 'b'], ['acting', 'wild'], ['me', 'child'], ['me', 'now'], ['call', 'me'], ['cats', 'meow'], ['cats', 'meow'], ['the', 'jive'], ['the', 'thighs'], ['a', 'lie'], ['the', '5'], ['we', 'drive'], ['i', 'slick'], ['are', 'sick'], ['dkny', 'kicks'], ['my', 'clique'], ['and', 'bounce'], ['bank', 'account']]\n",
      "[['i', 'try'], ['it', 'right'], ['even', 'better'], ['day', 'someday'], ['but', 'tomorrow'], ['i', 'know'], ['a', 'hassle'], ['of', 'paxil'], ['clap', 'you'], ['clap', 'too'], ['made', 'it'], ['it', 'confiscated'], ['take', 'powder'], ['take', 'showers'], ['8', 'hours'], ['the', 'glass'], ['that', 'cash'], ['a', 'smash'], ['on', 'crash'], ['was', '911'], ['on', 'dun'], ['and', 'run'], ['that', 'dumb'], ['i', 'try'], ['it', 'right'], ['even', 'better'], ['day', 'someday'], ['but', 'tomorrow'], ['i', 'know'], ['breeze', 'through'], ['believe', 'you'], ['that', 'g2'], ['letters', 'gq'], ['peachblue', 'hebrew'], ['steep', 'woo'], ['creep', 'through'], ['shittin', 'peeew'], ['need', 'you'], ['the', 'pain'], ['or', 'fame'], ['the', 'same'], ['get', 'changed'], ['mel', 'mel'], ['fell', 'hell'], ['12', 'cells'], ['the', 'phones'], ['at', 'home'], ['i', 'try'], ['it', 'right'], ['even', 'better'], ['day', 'someday'], ['but', 'tomorrow'], ['i', 'know'], ['the', 'ballparks'], ['cross', 'sharks'], ['lost', 'ark'], ['cross', 'narcs'], ['porsche', 'box'], ['poor', 'pops'], ['four', 'tops'], ['the', 'scanners'], ['your', 'hammers'], ['watch', 'cameras'], ['watch', 'grandma'], ['watch', 'santa'], ['watch', 'santana'], ['i', 'try'], ['it', 'right'], ['even', 'better'], ['day', 'someday'], ['but', 'tomorrow'], ['i', 'know'], ['little', 'tent'], ['climbed', 'over'], ['got', 'over'], ['not', 'over'], ['comin', 'cam'], ['running', 'man'], ['running', 'man'], ['duhduh', 'man'], ['jack', 'city'], ['cops', 'crash'], ['this', 'road'], ['this', 'road'], ['with', 'os'], ['with', 'wholes'], ['my', 'hoes'], ['and', 'roll'], ['the', 'o'], ['in', 'dough'], ['the', 'paperrun'], ['to', 'come'], ['has', 'come'], ['is', 'come'], ['the', 'ones'], ['other', 'motherfuckers'], ['shame', 'cuz']]\n",
      "[['yeah'], ['mind', 'yeah'], ['mind', 'yeah'], ['thats', 'right'], ['my', 'mind'], ['thats', 'right'], ['mind', 'bitch'], ['you', 'know'], ['mind', 'bitch'], ['mind', 'bitch'], ['my', 'mind'], ['of', 'ayy'], ['yeah'], ['awe', 'yeah'], ['a', 'wish'], ['jr', 'brr'], ['rich', 'yeah'], ['the', 'shit'], ['paper', 'thick'], ['i', 'know'], ['potatohead', 'wimp'], ['dip', 'gone'], ['just', 'strength'], ['one', 'two'], ['grip', 'yeah'], ['my', 'wrist'], ['wrist', 'haha'], ['pimp', 'yeah'], ['the', 'market'], ['we', 'talkin'], ['yeah'], ['bitches', 'yeah'], ['bitch', 'yeah'], ['fuck', 'bitches'], ['get', 'money'], ['get', 'money'], ['yeah'], ['how', 'uh'], ['a', 'snowplow'], ['your', 'time'], ['blowjobs', 'yeah'], ['the', 'cops'], ['pots', 'bitch'], ['what', 'up'], ['paid', 'yeah'], ['the', 'grave'], ['pays', 'yeah'], ['rays', 'bitch'], ['date', 'damn'], ['way', 'yeah'], ['my', 'birthday'], ['heard', 'me'], ['person', 'nigga'], ['yeah'], ['fuck', 'bitches'], ['bitch', 'yeah'], ['fuck', 'bitches'], ['get', 'money'], ['get', 'money'], ['dollar', 'okay'], ['her', 'okay'], ['problem', 'yeah'], ['pradas', 'uhuh'], ['modest', 'yeah'], ['it', 'bitch'], ['profit', 'yeah'], ['hide', 'me'], ['it', 'yeah'], ['to', 'you'], ['do', 'uh'], ['baby', 'yeah'], ['baby', 'yeah'], ['love', 'it'], ['public', 'hah'], ['with', 'nothin'], ['the', 'money'], ['yeah'], ['fuck', 'bitches'], ['money', 'yeah'], ['fuck', 'bitches'], ['get', 'money'], ['get', 'money']]\n",
      "[['this', 'large'], ['the', 'projs'], ['at', 'large'], ['da', 'bars'], ['get', 'me'], ['silicon', 'titty'], ['with', 'me'], ['fit', 'me'], ['with', 'me'], ['with', 'me'], ['with', 'me'], ['with', 'me'], ['with', 'me'], ['on', 'whitney'], ['boned', 'britney'], ['get', 'me'], ['yeah'], ['fucked', 'with'], ['fuck', 'with'], ['bump', 'with'], ['its', 'fabolous'], ['that', 'guy'], ['that', 'fly'], ['that', 'guy'], ['at', 'my'], ['seen', 'since'], ['little', 'flow'], ['uh', 'huh'], ['little', 'though'], ['itll', 'blow'], ['little', 'bro'], ['little', 'hoes'], ['on', 'broads'], ['the', 'god'], ['its', 'hard'], ['and', 'cards'], ['regards', 'nigga'], ['fucked', 'with'], ['fuck', 'with'], ['bump', 'with'], ['its', 'fabolous'], ['uh', 'nigga'], ['by', 'now'], ['i', 'be'], ['but', 'um'], ['that', 'streetfamily'], ['street', 'family'], ['uh', 'brooklyn'], ['to', 'brooklyn'], ['ha', 'ha']]\n"
     ]
    }
   ],
   "source": [
    "# lyrics['end words'][1000]\n",
    "for i in range(lyrics.shape[1]):\n",
    "    print(lyrics['end words'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we make the new function that will use the phoneme dictionary to annotate the phonemes of the words\n",
    "\n",
    "def translate_to_phonemes(end_words):\n",
    "    end_words_optimized = []\n",
    "    for end_word in end_words:\n",
    "        if len(end_word) == 2:\n",
    "            end_word_1 = word_phoneme_dict.get(end_word[0])\n",
    "            end_word_2 = word_phoneme_dict.get(end_word[1])\n",
    "            end_words_optimized.append([end_word_1, end_word_2])\n",
    "        elif len(end_word) == 1:\n",
    "            end_word_1 = word_phoneme_dict.get(end_word[0])\n",
    "            end_words_optimized.append([end_word_1])\n",
    "    return end_words_optimized\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics['end words phonemes'] = lyrics['end words'].apply(translate_to_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['JH EH1 D IY2', 'M AY1 N D'],\n",
       " ['AH1 V', 'M AE1 N K AY1 N D'],\n",
       " ['IH0 N', 'HH EH1 L'],\n",
       " ['W IH1 DH', 'M IY1'],\n",
       " ['Y AO1 R', 'B OW1 N Z'],\n",
       " ['AE1 Z', 'S T OW1 N'],\n",
       " ['AE1 T', 'HH OW1 M'],\n",
       " ['K IH1 L ER0 Z', 'R OW1 M'],\n",
       " ['T R AE1 P', 'M IY1'],\n",
       " ['W IY1', 'IH2 R AE1 K IY0'],\n",
       " ['D AA1 R K N AH0 S', 'P AE1 S AH0 Z'],\n",
       " ['M AH1 D IY0', 'AE1 SH AH0 Z'],\n",
       " ['IH1 Z', 'S IH1 K'],\n",
       " ['G AA1 Z AH0', 'S T R IH1 P'],\n",
       " ['T UW1', 'EH1 M'],\n",
       " ['AH0 N D', 'AY0 R EY1 N IY0 AH0 N Z'],\n",
       " ['DH AH0', 'P AE1 D'],\n",
       " [None, 'SH AA1 B AA0 Z'],\n",
       " ['W IH1 DH', None],\n",
       " ['AH0', 'G R UW1 P'],\n",
       " ['Y UW1', 'B IY1'],\n",
       " ['Y UW1', 'S IY1'],\n",
       " ['G OW1', 'AW1 T'],\n",
       " ['Y UW1', 'B IY1'],\n",
       " ['G OW1', 'AW1 T'],\n",
       " ['Y UW1', 'S IY1'],\n",
       " ['Y AO1 R', 'TH AO1 T S'],\n",
       " ['AE1 N AH0 M AH0 L', 'K L AO1 TH'],\n",
       " [None, 'F AO1 R S'],\n",
       " ['P EH1 R AH0 B AH0 L Z', 'L AO1 S T'],\n",
       " ['L AH1 NG Z', 'AE1 T'],\n",
       " ['P AH1 N', 'B AE1 K'],\n",
       " [None, 'DH AE1 T'],\n",
       " ['G AH1 N', 'R AE1 P'],\n",
       " ['AY1', 'T R AH1 S T'],\n",
       " ['DH EY1', 'B AH1 S T'],\n",
       " ['R AE1 P', 'N AW1'],\n",
       " ['R AE1 P', 'N AW1'],\n",
       " ['B AE1 K', 'D AW1 N'],\n",
       " ['G AE1 T', 'S AW1 N D'],\n",
       " ['F R EY1 M D', 'M AH0 M IY1 Y AH0'],\n",
       " ['AH0 N D', 'HH IY1 T ER0 Z'],\n",
       " ['Y UW1', 'B IY1'],\n",
       " ['Y UW1', 'S IY1'],\n",
       " ['G OW1', 'AW1 T'],\n",
       " ['Y UW1', 'B IY1'],\n",
       " ['G OW1', 'AW1 T'],\n",
       " ['Y UW1', 'S IY1'],\n",
       " ['B AY2 AH0 L AA1 JH IH0 K AH0 L', 'T EH1 R ER0 IH0 S T'],\n",
       " ['T EH1 R ER0', 'IH1 Z'],\n",
       " ['L AY1 K', 'TH EH1 R AH0 P IH0 S T S'],\n",
       " ['N EH1 V ER0', 'S N IH1 CH'],\n",
       " ['B ER0 EH1 T AH0', 'S P IH1 T S'],\n",
       " ['DH AH0', 'B IH1 CH'],\n",
       " ['AH0 N D', 'CH AA1 P ER0 Z'],\n",
       " ['AH1 V', None],\n",
       " ['DH EH1 M', 'W AH1 N'],\n",
       " ['AH0', 'G AH1 N'],\n",
       " ['IH1 Z', None],\n",
       " ['AE1 Z', 'W EH1 P AH0 N Z'],\n",
       " ['P R AA1 F AH0 T S', 'B IH0 F AO1 R'],\n",
       " ['AH1 V', 'W AO1 R'],\n",
       " ['D IH1 F ER0 AH0 N T', 'D IH0 G R IY1 Z'],\n",
       " ['DH AE1 N', 'S IY1 Z'],\n",
       " ['G OW1', 'AW1 T'],\n",
       " ['G AA1 N AH0', 'G OW1'],\n",
       " ['G OW1', 'AW1 T'],\n",
       " ['OW1', 'OW1']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics['end words phonemes'][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1. Some words are not in the dictionary - what to do?\n",
    "2. How to lable the scheme? (practically)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling and Extraction\n",
    "Current experiment is hold with BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Killa Cam, Killa Cam, Cam\\nKilla Cam, Killa Ca...\n",
       "1        \\nYeah, hah, yeah, Roc-A-Fella\\nWe invite you ...\n",
       "2        Maybe cause I'm eatin\\nAnd these bastards fien...\n",
       "3        \\nUgh, Killa!\\nBaby!\\nKanye, this that 1970s H...\n",
       "4        So they ask me\\n\"Young boy\\nWhat you gon' do t...\n",
       "                               ...                        \n",
       "39643    It's real, did you ever see that type of nigga...\n",
       "39644    There a toker, under the numb, scumb looker\\nG...\n",
       "39645    Dear God, I wonder can you save me?\\nI'm buggi...\n",
       "39646    With my x-ray vision\\nSee through you lames fo...\n",
       "39647    Verse One:\\n\\nI wake up to another day of life...\n",
       "Name: lyrics, Length: 39648, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lyrics['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 14:35:51.724885: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/zhenyabudnyk/PycharmProjects/LyrAIX/venv/lib/python3.8/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n",
      "/Users/zhenyabudnyk/PycharmProjects/LyrAIX/venv/lib/python3.8/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n",
      "/Users/zhenyabudnyk/PycharmProjects/LyrAIX/venv/lib/python3.8/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n",
      "/Users/zhenyabudnyk/PycharmProjects/LyrAIX/venv/lib/python3.8/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from bertopic import BERTopic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "# from tqdm import tqdm\n",
    "#\n",
    "# docs = fetch_20newsgroups(subset='test',  remove=('headers', 'footers', 'quotes'))['data']\n",
    "# nlp = spacy.load('en_core_web_sm', exclude=['tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer'])\n",
    "#\n",
    "# topic_model = BERTopic(embedding_model=nlp)\n",
    "# with tqdm(total=len(docs), desc=\"Fitting topic model\") as pbar:\n",
    "#     topics, probs = tqdm(topic_model.fit_transform(docs), total=len(docs), leave=False)\n",
    "#\n",
    "# fig = topic_model.visualize_topics()\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Fitting topic model:   0%|          | 0/39648 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "docs = lyrics['lyrics']\n",
    "nlp = spacy.load('en_core_web_md', exclude=['tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer'])\n",
    "\n",
    "\n",
    "topic_model = BERTopic(embedding_model=nlp)\n",
    "with tqdm(total=len(docs), desc=\"Fitting topic model\") as pbar:\n",
    "    topics, probs = tqdm(topic_model.fit_transform(docs), total=len(docs), leave=False)\n",
    "\n",
    "# topics, probs = topic_model.fit_transform(docs)\n",
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affect labeling\n",
    "Idea here is to use NRC labels and use majority score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Specify the file path and name\n",
    "file_path = '../NRC-VAD-Lexicon/BipolarScale/NRC-VAD-Lexicon.txt'\n",
    "\n",
    "# Create an empty dictionary to store the word-phoneme mappings\n",
    "affect_dictionary = {}\n",
    "\n",
    "encodings = ['utf-8', 'latin-1', 'utf-16', 'cp1252']\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    #print(line)\n",
    "                    split = line.split()\n",
    "                    if len(split) == 4:\n",
    "                        affect_dictionary[split[0]] = np.array([float(split[1]), float(split[2]), float(split[3])])\n",
    "                    elif len(split) == 5:\n",
    "                        affect_dictionary[split[0]+\" \"+split[1]] = np.array([float(split[2]), float(split[3]), float(split[4])])\n",
    "                    else:\n",
    "                        affect_dictionary[split[0]+ \" \"+split[1]+ \" \"+split[2]] = np.array([float(split[3]), float(split[4]), float(split[5])])\n",
    "            # break\n",
    "    except UnicodeDecodeError:\n",
    "        print('Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(affect_dictionary.get('love'))\n",
    "print(len(affect_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the algorithm is easy, first we take the lyrics, clean it from the newline characters, split it into words, then we iterate through the words and calculate the majority score. If the word is present in the affect dictionary - we take it, if not- ciao bambino!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_affect(lyric):\n",
    "    lyric = re.sub(r'[^A-Za-z0-9\\s]', '', lyric) # remove special chars\n",
    "    lyric = lyric.lower()\n",
    "    lyric = lyric.split('\\n') # split by new lines\n",
    "    lyric = list(filter(lambda line: line != '', lyric)) # delete an empty line\n",
    "    majority_score = np.zeros(3)\n",
    "    count_of_words = 0\n",
    "    for i, line in enumerate(lyric):\n",
    "        line = line.split()\n",
    "        for word in line:\n",
    "            if word in affect_dictionary.keys():\n",
    "                majority_score += affect_dictionary.get(word)\n",
    "                count_of_words+= 1\n",
    "    # print(count_of_words)\n",
    "    return majority_score / count_of_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lyrics['affect majority score'] = lyrics['lyrics'].apply(compute_affect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lyrics['affect majority score'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "Each song is parsed, each word is checked if it is in the dictionary, if it is - it is added to the aggregate value of the song, finally, this aggregate value is divided by amount of words from the song that are present in the dicitonary. Example - {12, -15, 10} - 5 words - hence {12/5, -15/5, 10/5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "vectors = lyrics['affect majority score'].values\n",
    "\n",
    "# Preprocess the vectors and convert to a valid NumPy array\n",
    "processed_vectors = []\n",
    "for vector in vectors:\n",
    "    # Check if the vector is a valid three-dimensional array\n",
    "    if isinstance(vector, np.ndarray) and vector.shape == (3,):\n",
    "        processed_vectors.append(vector)\n",
    "\n",
    "# Convert the processed vectors to a NumPy array\n",
    "vectors_array = np.array(processed_vectors)\n",
    "\n",
    "# Extract the x, y, and z components from the vectors array\n",
    "valence = vectors_array[:, 0]\n",
    "arousal = vectors_array[:, 1]\n",
    "dominance = vectors_array[:, 2]\n",
    "\n",
    "# Plot the vectors\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(valence, arousal, dominance, 'bo')\n",
    "ax.scatter(valence, arousal, dominance, color='r')\n",
    "\n",
    "# Set labels for each axis\n",
    "ax.set_xlabel('valence')\n",
    "ax.set_ylabel('arousal')\n",
    "ax.set_zlabel('dominance')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
