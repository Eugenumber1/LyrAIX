{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0922b053-3f65-4657-abea-d18bbf7cd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "lyrics = pd.read_csv('song_lyrics_lemmatized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da4b2bc-8276-424c-b7a6-4c3c5624dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing to the list: 100%|██████████| 5334078/5334078 [00:38<00:00, 139469.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['watchin', 'every', 'watchin', 'closely', 'butter', 'bread', 'wanna', 'toast', 'keep', 'head', 'supposed', 'sidetracked', 'clapped', 'close', 'foot', 'sleep', 'tired', 'feel', 'wired', 'like', 'codeine', 'day', 'brother', 'gotta', 'admire', 'four', 'fiend', 'away', 'pain', 'wish', 'quick', 'see', 'sellin', 'caine', 'til', 'brain', 'fried', 'fricassee', 'lie', 'time', 'never', 'bothered', 'bar', 'gettin', 'properly', 'squad', 'lack', 'respect', 'authority', 'laughin', 'hard', 'happy', 'escapin', 'poverty', 'however', 'brief', 'know', 'game', 'valley', 'peak', 'expectation', 'dip', 'precipitation', 'stack', 'chip', 'hardly', 'youth', 'used', 'soon', 'see', 'mill', 'big', 'willie', 'game', 'ha', 'grown', 'prefer', 'call', 'william', 'illin', 'revenue', 'rayful', 'edmond', 'like', 'channel', 'news', 'round', 'seven', 'jewel', 'head', 'dead', 'mic', 'forgettin', 'ever', 'knew', 'convenient', 'amnesia', 'suggest', 'call', 'lawyer', 'know', 'procedure', 'lock', 'body', 'trap', 'mind', 'easily', 'explain', 'adapt', 'crime', 'rather', 'die', 'enormous', 'live', 'dormant', 'live', 'main', 'event', 'bet', 'trip', 'maui', 'presidential', 'suite', 'residential', 'weekend', 'confidentially', 'speakin', 'code', 'since', 'sense', 'peekin', 'nsx', 'rental', 'fooled', 'game', 'mental', 'town', 'dog', 'tryin', 'viva', 'la', 'vega', 'see', 'later', 'table', 'meet', 'one', 'start', 'way', 'fraud', 'present', 'gamblin', 'pleasant', 'time', 'sippin', 'margarita']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lyrics_corpus_tokenized = list()\n",
    "for song in tqdm(lyrics['tokenized, lemmatized, no bad words'], desc=\"writing to the list\"):\n",
    "    lyrics_corpus_tokenized.append(song.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n",
    "print(type(lyrics_corpus_tokenized[0]))\n",
    "print(lyrics_corpus_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77270b72-e43e-47c8-96c0-dd0f06ff177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_remove = {'verse', 'chorus', 'hook', 'bridge', 'intro', 'outro', 'pre-chorus', 'pre-hook', 'get', 'got'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6df1b4c-4659-48b0-96c9-d704cdfde755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "removing: 100%|██████████| 5334078/5334078 [00:32<00:00, 165134.52it/s]\n"
     ]
    }
   ],
   "source": [
    "lyrics_corpus_tokenized = [\n",
    "    [token for token in song if token not in words_to_remove]\n",
    "    for song in tqdm(lyrics_corpus_tokenized, desc=\"removing\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e67845e-ac19-4071-8e6d-0873c65a4c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dictionary: 100%|██████████| 5334078/5334078 [02:11<00:00, 40673.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Assuming you have a big list called 'big_list'\n",
    "  # Number of items to choose\n",
    "\n",
    "# Randomly select 20,000 items from the big list\n",
    "# lyric_corpus_tokenized = lyric_corpus_tokenized.tolist()\n",
    "\n",
    "tqdm_corpus = tqdm(lyrics_corpus_tokenized, desc=\"Creating dictionary\")\n",
    "dictionary = Dictionary(tqdm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c27f6d5-c0ee-4179-9dfb-4de0fbcda32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=100, no_above=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a2daef1-d470-472b-94e0-91bd2a116a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Gensim Corpus: 100%|██████████| 5334078/5334078 [01:24<00:00, 62870.07it/s] \n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import MmCorpus\n",
    "gensim_corpus = []\n",
    "with tqdm(total=len(lyrics_corpus_tokenized), desc=\"Creating Gensim Corpus\") as pbar:\n",
    "    for song in lyrics_corpus_tokenized:\n",
    "        doc = dictionary.doc2bow(song)\n",
    "        gensim_corpus.append(doc)\n",
    "        pbar.update(1)\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33b34501-da33-4d84-a5c4-12294d460b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1124.63 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from gensim.models import LdaModel\n",
    "import random\n",
    "\n",
    "start_time = time.time()\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "num_topics = 4\n",
    "sample_size = 500000\n",
    "\n",
    "\n",
    "gensim2 = random.sample(gensim_corpus, sample_size)\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=gensim2,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Training time: {:.2f} seconds\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4b270c5-79cd-465a-a4fc-63d68e0abeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gensim.models import LdaModel\n",
    "import random\n",
    "# lda_model = LdaModel.load(\"lda_model_topics_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8e660c9-0324-4508-b7be-79bfeed27e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim_models as gensimvis\n",
    "# vis_data = gensimvis.prepare(lda_model, gensim_corpus, dictionary)\n",
    "# pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9665e0b-acc6-433b-8352-405de7c8982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pyLDAvis.save_html(vis_data, './Lyrics_LDA_'+ '4' +'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb6788d2-8a50-4897-8206-0808960d7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save(\"lda_model_4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951855c-7443-49e0-b77a-5b900dcab2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['life and relationships', 'money and authority', 'general', 'religion and society']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed07e7a-3e65-4ef0-87d1-b759932844c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting topics:  44%|████▍     | 2360193/5334078 [04:23<05:14, 9450.68it/s] "
     ]
    }
   ],
   "source": [
    "predicted_topics = list()\n",
    "with tqdm(total=len(gensim_corpus), desc=\"Predicting topics\") as pbar:\n",
    "    for song in gensim_corpus:\n",
    "        topic_dist = lda_model.get_document_topics(song)\n",
    "        predicted_topics.append(topic_dist)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500aa0e5-76ff-4cb2-8bf3-046659e4ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices = []\n",
    "for vector in predicted_topics:\n",
    "    max_tuple = max(vector, key=lambda t: t[1])\n",
    "    max_indices.append(topics[max_tuple[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34059e73-17dc-400d-8f4d-8f487ee5a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_indices[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b33b8e-4c3d-4f1c-a0a8-c59bb4cd6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics['topic'] = max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7c1a8-b0d8-45b7-86ba-42ee360f9b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = lyrics['predicted topics'].value_counts()['family and religion']\n",
    "# print(count, \" family and religion\")\n",
    "\n",
    "count = lyrics['topic'].value_counts()['life and relationships']\n",
    "print(count, \" life and relationships\")\n",
    "count = lyrics['topic'].value_counts()['money and authority']\n",
    "print(count, \" money and authority\")\n",
    "count = lyrics['topic'].value_counts()['general']\n",
    "print(count, \" general\")\n",
    "count = lyrics['topic'].value_counts()['religion and society']\n",
    "print(count, \" religion and society\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f28573-a8db-47c2-8013-84f8712d79b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics['topic vectors'] = predicted_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce16ed-6684-45b2-b2e7-5d5bc7743ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics.to_csv('song_topics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4399a-c5a8-4ad1-b30a-7fa45b209885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
