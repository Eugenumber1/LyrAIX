{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8fd4090-c6f1-4ae4-8511-b577a43bbbdd",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a0affc0-6999-4e2d-a93b-4ef26f83876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lyrics = pd.read_csv('/Users/zhenyabudnyk/PycharmProjects/LyrAIX/Thesis/Research Questions/RQ1/prompts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f982d53-c088-48a2-82ac-8675d179a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "lyric_corpus = lyrics['results']\n",
    "lyric_corpus_tokenized = []\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for lyric in lyric_corpus:\n",
    "    tokenized_lyric = tokenizer.tokenize(lyric.lower())\n",
    "    lyric_corpus_tokenized.append(tokenized_lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4dc5fa-1d18-485e-ab9a-a704a2a1b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,song in enumerate(lyric_corpus_tokenized):\n",
    "    filtered_song = []\n",
    "    for token in song:\n",
    "        if len(token) > 2 and not token.isnumeric():\n",
    "            filtered_song.append(token)\n",
    "    lyric_corpus_tokenized[s] = filtered_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3522e07c-0fd0-4f2a-b9e6-e9f6ba077b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatizing lyrics: 100%|██████████| 300/300 [00:02<00:00, 147.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for s, song in enumerate(tqdm(lyric_corpus_tokenized, desc=\"Lemmatizing lyrics\")):\n",
    "    lemmatized_tokens = []\n",
    "    for token in song:\n",
    "        lemmatized_tokens.append(lemmatizer.lemmatize(token))\n",
    "    lyric_corpus_tokenized[s] = lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec237dbd-b044-4386-b0af-1cf4dc9b2ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lying', 'lying', 'the', 'shadow', 'flying', 'flying', 'the', 'sky', 'can', 'stop', 'wondering', 'what', 'got', 'beautiful', 'beautiful', 'can', 'stop', 'chasing', 'dream', 'lying', 'lying', 'the', 'shadow', 'flying', 'flying', 'the', 'sky', 'can', 'stop', 'wondering', 'what', 'got', 'beautiful', 'beautiful', 'can', 'stop', 'chasing', 'dream']\n"
     ]
    }
   ],
   "source": [
    "print(lyric_corpus_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f2c7d4c-aee4-4700-aaec-4ef597256f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics['lemmatized'] = lyric_corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e780d09-c77d-448f-89bb-403eaae5904f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0 Valence Arousal Dominance    Part  \\\n0               0             0           0    High     Low    Medium  Chorus   \n1               1             1           1    High  Medium       Low  Bridge   \n2               2             2           2    High  Medium      High  Chorus   \n3               3             3           3  Medium     Low      High  Bridge   \n4               4             4           4  Medium    High    Medium  Chorus   \n..            ...           ...         ...     ...     ...       ...     ...   \n295           295           295         295    High    High       Low   Verse   \n296           296           296         296    High     Low      High   Verse   \n297           297           297         297     Low    High    Medium   Verse   \n298           298           298         298  Medium  Medium       Low   Verse   \n299           299           299         299    High    High      High   Verse   \n\n                          Artist                   Topic      Explicitness  \\\n0                     Sofya Wang  life and relationships            Normal   \n1                    Chiddy Bang  life and relationships            Normal   \n2                        Shwayze  life and relationships            Normal   \n3                   Dove Cameron                 general            Normal   \n4                         Weezer                 general            Normal   \n..                           ...                     ...               ...   \n295             The Irish Rovers                 general            Normal   \n296  Genius English Translations  life and relationships  Explicit content   \n297           Tiana Major9 & SiR                 general            Normal   \n298                  Spacey Jane    religion and society  Explicit content   \n299                   Chief Keef  life and relationships            Normal   \n\n                                                Scheme  \\\n0                                      0-0-0-1-0-0-1-1   \n1                                      0-0-1-2-3-4-5-6   \n2                                        0-1-2-0-3-3-4   \n3                                          0-1-2-1-1-1   \n4                                                    0   \n..                                                 ...   \n295  0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18...   \n296                                            0-0-0-0   \n297                                            0-1-2-1   \n298                                            0-1-2-3   \n299                                      0-1-1-2-2-1-3   \n\n                                           Instruction  \\\n0    Generate a Chorus of song lyrics in the style ...   \n1    Generate a Bridge of song lyrics in the style ...   \n2    Generate a Chorus of song lyrics in the style ...   \n3    Generate a Bridge of song lyrics in the style ...   \n4    Generate a Chorus of song lyrics in the style ...   \n..                                                 ...   \n295  Generate a Verse of song lyrics in the style o...   \n296  Generate a Verse of song lyrics in the style o...   \n297  Generate a Verse of song lyrics in the style o...   \n298  Generate a Verse of song lyrics in the style o...   \n299  Generate a Verse of song lyrics in the style o...   \n\n                                               results predicted explicitness  \\\n0    We're lying, we're lying in the shadows\\nI'm f...                 Normal   \n1    You don't wanna party\\nWhy you tryna party\\nI ...                 Normal   \n2    And if you run from me, baby, run from me\\nYou...                 Normal   \n3    Swing on by, all you can hear is me\\nLet's get...                 Normal   \n4            Singing like a symphony in a restaurant\\n                 Normal   \n..                                                 ...                    ...   \n295  Down to the wire\\nI'm down to the wire\\nI'm do...                 Normal   \n296  Well, I want to taste my eyes\\nI wanna see the...                 Normal   \n297  It's a big world, but I gotta do my thing\\nThe...                 Normal   \n298  Him to me a mwah a cryd for the people that kn...                 Normal   \n299  I been going every day, all the day\\nGot a lot...                 Normal   \n\n                                   predicted scheme  \\\n0                               0-1-2-3-4-5-6-7-8-9   \n1                                   0-1-2-3-4-2-4-5   \n2                                     0-1-2-3-4-5-4   \n3                                       0-1-2-3-4-5   \n4                                                 0   \n..                                              ...   \n295  0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18   \n296                                         0-0-1-2   \n297                                         0-1-2-3   \n298                                         0-0-0-0   \n299                                   0-1-2-3-4-5-3   \n\n                                            lemmatized  \n0    [lying, lying, the, shadow, flying, flying, th...  \n1    [you, don, wanna, party, why, you, tryna, part...  \n2    [and, you, run, from, baby, run, from, you, co...  \n3    [swing, all, you, can, hear, let, get, the, pa...  \n4                [singing, like, symphony, restaurant]  \n..                                                 ...  \n295  [down, the, wire, down, the, wire, down, the, ...  \n296  [well, want, taste, eye, wanna, see, them, tea...  \n297  [big, world, but, gotta, thing, they, don, see...  \n298  [him, mwah, cryd, for, the, people, that, know...  \n299  [been, going, every, day, all, the, day, got, ...  \n\n[300 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.2</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>Valence</th>\n      <th>Arousal</th>\n      <th>Dominance</th>\n      <th>Part</th>\n      <th>Artist</th>\n      <th>Topic</th>\n      <th>Explicitness</th>\n      <th>Scheme</th>\n      <th>Instruction</th>\n      <th>results</th>\n      <th>predicted explicitness</th>\n      <th>predicted scheme</th>\n      <th>lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Medium</td>\n      <td>Chorus</td>\n      <td>Sofya Wang</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-0-0-1-0-0-1-1</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>We're lying, we're lying in the shadows\\nI'm f...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9</td>\n      <td>[lying, lying, the, shadow, flying, flying, th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Bridge</td>\n      <td>Chiddy Bang</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-0-1-2-3-4-5-6</td>\n      <td>Generate a Bridge of song lyrics in the style ...</td>\n      <td>You don't wanna party\\nWhy you tryna party\\nI ...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-2-4-5</td>\n      <td>[you, don, wanna, party, why, you, tryna, part...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>Chorus</td>\n      <td>Shwayze</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-1-2-0-3-3-4</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>And if you run from me, baby, run from me\\nYou...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-4</td>\n      <td>[and, you, run, from, baby, run, from, you, co...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Bridge</td>\n      <td>Dove Cameron</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-1-1-1</td>\n      <td>Generate a Bridge of song lyrics in the style ...</td>\n      <td>Swing on by, all you can hear is me\\nLet's get...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5</td>\n      <td>[swing, all, you, can, hear, let, get, the, pa...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Chorus</td>\n      <td>Weezer</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>Singing like a symphony in a restaurant\\n</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>[singing, like, symphony, restaurant]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>295</td>\n      <td>295</td>\n      <td>295</td>\n      <td>High</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Verse</td>\n      <td>The Irish Rovers</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18...</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Down to the wire\\nI'm down to the wire\\nI'm do...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18</td>\n      <td>[down, the, wire, down, the, wire, down, the, ...</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>296</td>\n      <td>296</td>\n      <td>296</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Verse</td>\n      <td>Genius English Translations</td>\n      <td>life and relationships</td>\n      <td>Explicit content</td>\n      <td>0-0-0-0</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Well, I want to taste my eyes\\nI wanna see the...</td>\n      <td>Normal</td>\n      <td>0-0-1-2</td>\n      <td>[well, want, taste, eye, wanna, see, them, tea...</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>297</td>\n      <td>297</td>\n      <td>297</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Verse</td>\n      <td>Tiana Major9 &amp; SiR</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-1</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>It's a big world, but I gotta do my thing\\nThe...</td>\n      <td>Normal</td>\n      <td>0-1-2-3</td>\n      <td>[big, world, but, gotta, thing, they, don, see...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>298</td>\n      <td>298</td>\n      <td>298</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Verse</td>\n      <td>Spacey Jane</td>\n      <td>religion and society</td>\n      <td>Explicit content</td>\n      <td>0-1-2-3</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Him to me a mwah a cryd for the people that kn...</td>\n      <td>Normal</td>\n      <td>0-0-0-0</td>\n      <td>[him, mwah, cryd, for, the, people, that, know...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>299</td>\n      <td>299</td>\n      <td>299</td>\n      <td>High</td>\n      <td>High</td>\n      <td>High</td>\n      <td>Verse</td>\n      <td>Chief Keef</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-1-1-2-2-1-3</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>I been going every day, all the day\\nGot a lot...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-3</td>\n      <td>[been, going, every, day, all, the, day, got, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fbf329c-f4cc-4d2c-a7ba-ec9578fa6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyrics['tokenized, lemmatized, no bad words'] = lyric_corpus_tokenized\n",
    "lyrics.to_csv('/Users/zhenyabudnyk/PycharmProjects/LyrAIX/Thesis/Research Questions/RQ1/prompts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53b3dfd4-d502-43d6-a7ae-ad4111b530c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0 Valence Arousal Dominance    Part  \\\n0               0             0           0    High     Low    Medium  Chorus   \n1               1             1           1    High  Medium       Low  Bridge   \n2               2             2           2    High  Medium      High  Chorus   \n3               3             3           3  Medium     Low      High  Bridge   \n4               4             4           4  Medium    High    Medium  Chorus   \n..            ...           ...         ...     ...     ...       ...     ...   \n295           295           295         295    High    High       Low   Verse   \n296           296           296         296    High     Low      High   Verse   \n297           297           297         297     Low    High    Medium   Verse   \n298           298           298         298  Medium  Medium       Low   Verse   \n299           299           299         299    High    High      High   Verse   \n\n                          Artist                   Topic      Explicitness  \\\n0                     Sofya Wang  life and relationships            Normal   \n1                    Chiddy Bang  life and relationships            Normal   \n2                        Shwayze  life and relationships            Normal   \n3                   Dove Cameron                 general            Normal   \n4                         Weezer                 general            Normal   \n..                           ...                     ...               ...   \n295             The Irish Rovers                 general            Normal   \n296  Genius English Translations  life and relationships  Explicit content   \n297           Tiana Major9 & SiR                 general            Normal   \n298                  Spacey Jane    religion and society  Explicit content   \n299                   Chief Keef  life and relationships            Normal   \n\n                                                Scheme  \\\n0                                      0-0-0-1-0-0-1-1   \n1                                      0-0-1-2-3-4-5-6   \n2                                        0-1-2-0-3-3-4   \n3                                          0-1-2-1-1-1   \n4                                                    0   \n..                                                 ...   \n295  0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18...   \n296                                            0-0-0-0   \n297                                            0-1-2-1   \n298                                            0-1-2-3   \n299                                      0-1-1-2-2-1-3   \n\n                                           Instruction  \\\n0    Generate a Chorus of song lyrics in the style ...   \n1    Generate a Bridge of song lyrics in the style ...   \n2    Generate a Chorus of song lyrics in the style ...   \n3    Generate a Bridge of song lyrics in the style ...   \n4    Generate a Chorus of song lyrics in the style ...   \n..                                                 ...   \n295  Generate a Verse of song lyrics in the style o...   \n296  Generate a Verse of song lyrics in the style o...   \n297  Generate a Verse of song lyrics in the style o...   \n298  Generate a Verse of song lyrics in the style o...   \n299  Generate a Verse of song lyrics in the style o...   \n\n                                               results predicted explicitness  \\\n0    We're lying, we're lying in the shadows\\nI'm f...                 Normal   \n1    You don't wanna party\\nWhy you tryna party\\nI ...                 Normal   \n2    And if you run from me, baby, run from me\\nYou...                 Normal   \n3    Swing on by, all you can hear is me\\nLet's get...                 Normal   \n4            Singing like a symphony in a restaurant\\n                 Normal   \n..                                                 ...                    ...   \n295  Down to the wire\\nI'm down to the wire\\nI'm do...                 Normal   \n296  Well, I want to taste my eyes\\nI wanna see the...                 Normal   \n297  It's a big world, but I gotta do my thing\\nThe...                 Normal   \n298  Him to me a mwah a cryd for the people that kn...                 Normal   \n299  I been going every day, all the day\\nGot a lot...                 Normal   \n\n                                   predicted scheme  \\\n0                               0-1-2-3-4-5-6-7-8-9   \n1                                   0-1-2-3-4-2-4-5   \n2                                     0-1-2-3-4-5-4   \n3                                       0-1-2-3-4-5   \n4                                                 0   \n..                                              ...   \n295  0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18   \n296                                         0-0-1-2   \n297                                         0-1-2-3   \n298                                         0-0-0-0   \n299                                   0-1-2-3-4-5-3   \n\n                                            lemmatized  \n0    ['lying', 'lying', 'the', 'shadow', 'flying', ...  \n1    ['you', 'don', 'wanna', 'party', 'why', 'you',...  \n2    ['and', 'you', 'run', 'from', 'baby', 'run', '...  \n3    ['swing', 'all', 'you', 'can', 'hear', 'let', ...  \n4        ['singing', 'like', 'symphony', 'restaurant']  \n..                                                 ...  \n295  ['down', 'the', 'wire', 'down', 'the', 'wire',...  \n296  ['well', 'want', 'taste', 'eye', 'wanna', 'see...  \n297  ['big', 'world', 'but', 'gotta', 'thing', 'the...  \n298  ['him', 'mwah', 'cryd', 'for', 'the', 'people'...  \n299  ['been', 'going', 'every', 'day', 'all', 'the'...  \n\n[300 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.2</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>Valence</th>\n      <th>Arousal</th>\n      <th>Dominance</th>\n      <th>Part</th>\n      <th>Artist</th>\n      <th>Topic</th>\n      <th>Explicitness</th>\n      <th>Scheme</th>\n      <th>Instruction</th>\n      <th>results</th>\n      <th>predicted explicitness</th>\n      <th>predicted scheme</th>\n      <th>lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Medium</td>\n      <td>Chorus</td>\n      <td>Sofya Wang</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-0-0-1-0-0-1-1</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>We're lying, we're lying in the shadows\\nI'm f...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9</td>\n      <td>['lying', 'lying', 'the', 'shadow', 'flying', ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Bridge</td>\n      <td>Chiddy Bang</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-0-1-2-3-4-5-6</td>\n      <td>Generate a Bridge of song lyrics in the style ...</td>\n      <td>You don't wanna party\\nWhy you tryna party\\nI ...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-2-4-5</td>\n      <td>['you', 'don', 'wanna', 'party', 'why', 'you',...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>Chorus</td>\n      <td>Shwayze</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-1-2-0-3-3-4</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>And if you run from me, baby, run from me\\nYou...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-4</td>\n      <td>['and', 'you', 'run', 'from', 'baby', 'run', '...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Bridge</td>\n      <td>Dove Cameron</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-1-1-1</td>\n      <td>Generate a Bridge of song lyrics in the style ...</td>\n      <td>Swing on by, all you can hear is me\\nLet's get...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5</td>\n      <td>['swing', 'all', 'you', 'can', 'hear', 'let', ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Chorus</td>\n      <td>Weezer</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>Singing like a symphony in a restaurant\\n</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>['singing', 'like', 'symphony', 'restaurant']</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>295</td>\n      <td>295</td>\n      <td>295</td>\n      <td>High</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Verse</td>\n      <td>The Irish Rovers</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18...</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Down to the wire\\nI'm down to the wire\\nI'm do...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18</td>\n      <td>['down', 'the', 'wire', 'down', 'the', 'wire',...</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>296</td>\n      <td>296</td>\n      <td>296</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Verse</td>\n      <td>Genius English Translations</td>\n      <td>life and relationships</td>\n      <td>Explicit content</td>\n      <td>0-0-0-0</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Well, I want to taste my eyes\\nI wanna see the...</td>\n      <td>Normal</td>\n      <td>0-0-1-2</td>\n      <td>['well', 'want', 'taste', 'eye', 'wanna', 'see...</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>297</td>\n      <td>297</td>\n      <td>297</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Verse</td>\n      <td>Tiana Major9 &amp; SiR</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-1</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>It's a big world, but I gotta do my thing\\nThe...</td>\n      <td>Normal</td>\n      <td>0-1-2-3</td>\n      <td>['big', 'world', 'but', 'gotta', 'thing', 'the...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>298</td>\n      <td>298</td>\n      <td>298</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Verse</td>\n      <td>Spacey Jane</td>\n      <td>religion and society</td>\n      <td>Explicit content</td>\n      <td>0-1-2-3</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Him to me a mwah a cryd for the people that kn...</td>\n      <td>Normal</td>\n      <td>0-0-0-0</td>\n      <td>['him', 'mwah', 'cryd', 'for', 'the', 'people'...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>299</td>\n      <td>299</td>\n      <td>299</td>\n      <td>High</td>\n      <td>High</td>\n      <td>High</td>\n      <td>Verse</td>\n      <td>Chief Keef</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-1-1-2-2-1-3</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>I been going every day, all the day\\nGot a lot...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-3</td>\n      <td>['been', 'going', 'every', 'day', 'all', 'the'...</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38421f9a-2565-4907-9574-1447407ad6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics.to_csv('/Users/zhenyabudnyk/PycharmProjects/LyrAIX/Thesis/Research Questions/RQ1/prompts.csv', index=False) # the stopwords and very frequent and infrequent words are not removed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e7277-ab11-47e6-84b5-815dac3c2e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34bd0ca2-4882-424a-b9ef-7a7e143c0103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zhenyabudnyk/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47cb564-9613-4edd-81a0-ad7110a5b59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lying', 'lying', 'the', 'shadow', 'flying', 'flying', 'the', 'sky', 'can', 'stop', 'wondering', 'what', 'got', 'beautiful', 'beautiful', 'can', 'stop', 'chasing', 'dream', 'lying', 'lying', 'the', 'shadow', 'flying', 'flying', 'the', 'sky', 'can', 'stop', 'wondering', 'what', 'got', 'beautiful', 'beautiful', 'can', 'stop', 'chasing', 'dream']\n",
      "['you', 'don', 'wanna', 'party', 'why', 'you', 'tryna', 'party', 'ain', 'even', 'gotta', 'say', 'cause', 'you', 'probably', 'not', 'what', 'like', 'won', 'might', 'just', 'pas', 'and', 'don', 'care']\n",
      "['and', 'you', 'run', 'from', 'baby', 'run', 'from', 'you', 'could', 'live', 'good', 'life', 'for', 'but', 'you', 'can', 'run', 'from', 'baby', 'run', 'from', 'they', 'can', 'keep', 'locked', 'cage', 'but', 'you', 'can', 'run', 'from', 'baby', 'run', 'from', 'you', 'running', 'very', 'far', 'from', 'home', 'but', 'you', 'won', 'gonna', 'run', 'far', 'from', 'anyway']\n",
      "['swing', 'all', 'you', 'can', 'hear', 'let', 'get', 'the', 'party', 'started', 'and', 'back', 'school', 'big', 'shot', 'whatever', 'take', 'ain', 'gotta', 'what', 'they', 'say', 'ain', 'gotta', 'drive', 'the', 'jag', 'big', 'shot', 'whatever', 'take', 'ain', 'gotta', 'what', 'they', 'say', 'ain', 'gotta', 'drive', 'the', 'jag']\n",
      "['singing', 'like', 'symphony', 'restaurant']\n",
      "['been', 'down', 'down', 'down', 'riding', 'slow', 'pace', 'searching', 'for', 'the', 'light', 'been', 'down', 'down', 'down', 'trying', 'see', 'you', 'listening', 'been', 'down', 'down', 'down', 'but', 'still', 'standing', 'here', 'looking', 'for', 'sign', 'and', 'can', 'lose', 'trying', 'find', 'sign', 'but', 'can', 'lose', 'but', 'can', 'can', 'lose']\n",
      "['yeah', 'say', 'what', 'you', 'wanna', 'say', 'yeah', 'say', 'what', 'you', 'wanna', 'say', 'yeah', 'say', 'what', 'you', 'wanna', 'say', 'yeah', 'say', 'what', 'you', 'wanna', 'say']\n",
      "['boy', 'love', 'when', 'you', 'smile', 'hey', 'hey', 'boy', 'all', 'over', 'you', 'don', 'care', 'don', 'care', 'boy', 'love', 'when', 'you', 'pull', 'closer', 'yeah', 'boy', 'all', 'over', 'you', 'don', 'care', 'don', 'care', 'boy', 'all', 'over', 'you', 'don', 'care', 'don', 'care', 'boy', 'love', 'when', 'you', 'pull', 'closer', 'yeah', 'boy', 'all', 'over', 'you', 'don']\n",
      "['they', 'say', 'love', 'blind', 'love', 'blind', 'love', 'blind', 'love', 'blind']\n",
      "['got', 'lot', 'love', 'for', 'you', 'love', 'for', 'you', 'can', 'let', 'got', 'lot', 'love', 'for', 'you', 'love', 'for', 'you', 'said', 'can', 'forget', 'you']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(lyric_corpus_tokenized[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b7b4849-79db-4f1a-8471-57dd2f6865db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lyrics = pd.read_csv('/Users/zhenyabudnyk/PycharmProjects/LyrAIX/Thesis/Research Questions/RQ1/prompts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f53c63a0-815b-49f4-aab0-e7b8819d19d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing to the list: 100%|██████████| 300/300 [00:00<00:00, 93574.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['lying', 'lying', 'the', 'shadow', 'flying', 'flying', 'the', 'sky', 'can', 'stop', 'wondering', 'what', 'got', 'beautiful', 'beautiful', 'can', 'stop', 'chasing', 'dream', 'lying', 'lying', 'the', 'shadow', 'flying', 'flying', 'the', 'sky', 'can', 'stop', 'wondering', 'what', 'got', 'beautiful', 'beautiful', 'can', 'stop', 'chasing', 'dream']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "lyric_corpus_tokenized = list()\n",
    "for song in tqdm(lyrics['lemmatized'], desc=\"writing to the list\"):\n",
    "    lyric_corpus_tokenized.append(song.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n",
    "print(type(lyric_corpus_tokenized[0]))\n",
    "print(lyric_corpus_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bdfd30c-e134-45cf-9201-e4dc4746ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/zhenyabudnyk/PycharmProjects/LyrAIX/Thesis/Data Labeling/Explicitness Labeling/profanities.txt', 'r') as file:\n",
    "    prof_string = file.read().replace('\\n', '')\n",
    "    profanities = set(prof_string.split(\", \"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89035211-66a7-4c2c-afa1-0cc437a64830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "removing profanities: 100%|██████████| 300/300 [00:00<00:00, 45112.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def filter_song(song):\n",
    "    return [token for token in song if token not in profanities]\n",
    "\n",
    "lyric_corpus_tokenized = [\n",
    "    filter_song(song) for song in tqdm(lyric_corpus_tokenized, desc=\"removing profanities\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdc7e64f-797a-4c4d-a5f6-9bded4adab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "194\n",
      "<class 'set'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "removing stop words: 100%|██████████| 300/300 [00:00<00:00, 257688.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "new_stop_words = ['ooh','yeah','hey','whoa','woah', 'ohh', 'was', 'mmm', 'oooh','yah','yeh','mmm', 'hmm','deh','doh','jah','wa']\n",
    "stop_words.extend(new_stop_words)\n",
    "print(len(stop_words))\n",
    "stop_words = set(stop_words)\n",
    "print(len(stop_words))\n",
    "print(type(stop_words))\n",
    "\n",
    "for s,song in enumerate(tqdm(lyric_corpus_tokenized, desc=\"removing stop words\")):\n",
    "    filtered_text = []\n",
    "    for token in song:\n",
    "        if token not in stop_words:\n",
    "            filtered_text.append(token)\n",
    "    lyric_corpus_tokenized[s] = filtered_text\n",
    "\n",
    "# for i in range(10):\n",
    "#     print(lyric_corpus_tokenized[i])\n",
    "\n",
    "lyrics['tokenized, lemmatized, no bad words'] = lyric_corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0 Valence Arousal Dominance    Part  \\\n0               0             0           0    High     Low    Medium  Chorus   \n1               1             1           1    High  Medium       Low  Bridge   \n2               2             2           2    High  Medium      High  Chorus   \n3               3             3           3  Medium     Low      High  Bridge   \n4               4             4           4  Medium    High    Medium  Chorus   \n..            ...           ...         ...     ...     ...       ...     ...   \n295           295           295         295    High    High       Low   Verse   \n296           296           296         296    High     Low      High   Verse   \n297           297           297         297     Low    High    Medium   Verse   \n298           298           298         298  Medium  Medium       Low   Verse   \n299           299           299         299    High    High      High   Verse   \n\n                          Artist                   Topic      Explicitness  \\\n0                     Sofya Wang  life and relationships            Normal   \n1                    Chiddy Bang  life and relationships            Normal   \n2                        Shwayze  life and relationships            Normal   \n3                   Dove Cameron                 general            Normal   \n4                         Weezer                 general            Normal   \n..                           ...                     ...               ...   \n295             The Irish Rovers                 general            Normal   \n296  Genius English Translations  life and relationships  Explicit content   \n297           Tiana Major9 & SiR                 general            Normal   \n298                  Spacey Jane    religion and society  Explicit content   \n299                   Chief Keef  life and relationships            Normal   \n\n                                                Scheme  \\\n0                                      0-0-0-1-0-0-1-1   \n1                                      0-0-1-2-3-4-5-6   \n2                                        0-1-2-0-3-3-4   \n3                                          0-1-2-1-1-1   \n4                                                    0   \n..                                                 ...   \n295  0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18...   \n296                                            0-0-0-0   \n297                                            0-1-2-1   \n298                                            0-1-2-3   \n299                                      0-1-1-2-2-1-3   \n\n                                           Instruction  \\\n0    Generate a Chorus of song lyrics in the style ...   \n1    Generate a Bridge of song lyrics in the style ...   \n2    Generate a Chorus of song lyrics in the style ...   \n3    Generate a Bridge of song lyrics in the style ...   \n4    Generate a Chorus of song lyrics in the style ...   \n..                                                 ...   \n295  Generate a Verse of song lyrics in the style o...   \n296  Generate a Verse of song lyrics in the style o...   \n297  Generate a Verse of song lyrics in the style o...   \n298  Generate a Verse of song lyrics in the style o...   \n299  Generate a Verse of song lyrics in the style o...   \n\n                                               results predicted explicitness  \\\n0    We're lying, we're lying in the shadows\\nI'm f...                 Normal   \n1    You don't wanna party\\nWhy you tryna party\\nI ...                 Normal   \n2    And if you run from me, baby, run from me\\nYou...                 Normal   \n3    Swing on by, all you can hear is me\\nLet's get...                 Normal   \n4            Singing like a symphony in a restaurant\\n                 Normal   \n..                                                 ...                    ...   \n295  Down to the wire\\nI'm down to the wire\\nI'm do...                 Normal   \n296  Well, I want to taste my eyes\\nI wanna see the...                 Normal   \n297  It's a big world, but I gotta do my thing\\nThe...                 Normal   \n298  Him to me a mwah a cryd for the people that kn...                 Normal   \n299  I been going every day, all the day\\nGot a lot...                 Normal   \n\n                                   predicted scheme  \\\n0                               0-1-2-3-4-5-6-7-8-9   \n1                                   0-1-2-3-4-2-4-5   \n2                                     0-1-2-3-4-5-4   \n3                                       0-1-2-3-4-5   \n4                                                 0   \n..                                              ...   \n295  0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18   \n296                                         0-0-1-2   \n297                                         0-1-2-3   \n298                                         0-0-0-0   \n299                                   0-1-2-3-4-5-3   \n\n                                            lemmatized  \\\n0    ['lying', 'lying', 'the', 'shadow', 'flying', ...   \n1    ['you', 'don', 'wanna', 'party', 'why', 'you',...   \n2    ['and', 'you', 'run', 'from', 'baby', 'run', '...   \n3    ['swing', 'all', 'you', 'can', 'hear', 'let', ...   \n4        ['singing', 'like', 'symphony', 'restaurant']   \n..                                                 ...   \n295  ['down', 'the', 'wire', 'down', 'the', 'wire',...   \n296  ['well', 'want', 'taste', 'eye', 'wanna', 'see...   \n297  ['big', 'world', 'but', 'gotta', 'thing', 'the...   \n298  ['him', 'mwah', 'cryd', 'for', 'the', 'people'...   \n299  ['been', 'going', 'every', 'day', 'all', 'the'...   \n\n                   tokenized, lemmatized, no bad words  \n0    [lying, lying, shadow, flying, flying, sky, st...  \n1    [wanna, party, tryna, party, even, gotta, say,...  \n2    [run, baby, run, could, live, good, life, run,...  \n3    [swing, hear, let, get, party, started, back, ...  \n4                [singing, like, symphony, restaurant]  \n..                                                 ...  \n295  [wire, wire, wire, wire, wire, wire, wire, wir...  \n296  [well, want, taste, eye, wanna, see, tearfully...  \n297  [big, world, gotta, thing, see, lot, energy, g...  \n298  [mwah, cryd, people, know, world, world, world...  \n299  [going, every, day, day, got, lot, problem, go...  \n\n[300 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.2</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>Valence</th>\n      <th>Arousal</th>\n      <th>Dominance</th>\n      <th>Part</th>\n      <th>Artist</th>\n      <th>Topic</th>\n      <th>Explicitness</th>\n      <th>Scheme</th>\n      <th>Instruction</th>\n      <th>results</th>\n      <th>predicted explicitness</th>\n      <th>predicted scheme</th>\n      <th>lemmatized</th>\n      <th>tokenized, lemmatized, no bad words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Medium</td>\n      <td>Chorus</td>\n      <td>Sofya Wang</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-0-0-1-0-0-1-1</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>We're lying, we're lying in the shadows\\nI'm f...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9</td>\n      <td>['lying', 'lying', 'the', 'shadow', 'flying', ...</td>\n      <td>[lying, lying, shadow, flying, flying, sky, st...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Bridge</td>\n      <td>Chiddy Bang</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-0-1-2-3-4-5-6</td>\n      <td>Generate a Bridge of song lyrics in the style ...</td>\n      <td>You don't wanna party\\nWhy you tryna party\\nI ...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-2-4-5</td>\n      <td>['you', 'don', 'wanna', 'party', 'why', 'you',...</td>\n      <td>[wanna, party, tryna, party, even, gotta, say,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>Chorus</td>\n      <td>Shwayze</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-1-2-0-3-3-4</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>And if you run from me, baby, run from me\\nYou...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-4</td>\n      <td>['and', 'you', 'run', 'from', 'baby', 'run', '...</td>\n      <td>[run, baby, run, could, live, good, life, run,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Bridge</td>\n      <td>Dove Cameron</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-1-1-1</td>\n      <td>Generate a Bridge of song lyrics in the style ...</td>\n      <td>Swing on by, all you can hear is me\\nLet's get...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5</td>\n      <td>['swing', 'all', 'you', 'can', 'hear', 'let', ...</td>\n      <td>[swing, hear, let, get, party, started, back, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Chorus</td>\n      <td>Weezer</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>Singing like a symphony in a restaurant\\n</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>['singing', 'like', 'symphony', 'restaurant']</td>\n      <td>[singing, like, symphony, restaurant]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>295</td>\n      <td>295</td>\n      <td>295</td>\n      <td>High</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Verse</td>\n      <td>The Irish Rovers</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18...</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Down to the wire\\nI'm down to the wire\\nI'm do...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18</td>\n      <td>['down', 'the', 'wire', 'down', 'the', 'wire',...</td>\n      <td>[wire, wire, wire, wire, wire, wire, wire, wir...</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>296</td>\n      <td>296</td>\n      <td>296</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Verse</td>\n      <td>Genius English Translations</td>\n      <td>life and relationships</td>\n      <td>Explicit content</td>\n      <td>0-0-0-0</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Well, I want to taste my eyes\\nI wanna see the...</td>\n      <td>Normal</td>\n      <td>0-0-1-2</td>\n      <td>['well', 'want', 'taste', 'eye', 'wanna', 'see...</td>\n      <td>[well, want, taste, eye, wanna, see, tearfully...</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>297</td>\n      <td>297</td>\n      <td>297</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Verse</td>\n      <td>Tiana Major9 &amp; SiR</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-1</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>It's a big world, but I gotta do my thing\\nThe...</td>\n      <td>Normal</td>\n      <td>0-1-2-3</td>\n      <td>['big', 'world', 'but', 'gotta', 'thing', 'the...</td>\n      <td>[big, world, gotta, thing, see, lot, energy, g...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>298</td>\n      <td>298</td>\n      <td>298</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Verse</td>\n      <td>Spacey Jane</td>\n      <td>religion and society</td>\n      <td>Explicit content</td>\n      <td>0-1-2-3</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Him to me a mwah a cryd for the people that kn...</td>\n      <td>Normal</td>\n      <td>0-0-0-0</td>\n      <td>['him', 'mwah', 'cryd', 'for', 'the', 'people'...</td>\n      <td>[mwah, cryd, people, know, world, world, world...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>299</td>\n      <td>299</td>\n      <td>299</td>\n      <td>High</td>\n      <td>High</td>\n      <td>High</td>\n      <td>Verse</td>\n      <td>Chief Keef</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-1-1-2-2-1-3</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>I been going every day, all the day\\nGot a lot...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-3</td>\n      <td>['been', 'going', 'every', 'day', 'all', 'the'...</td>\n      <td>[going, every, day, day, got, lot, problem, go...</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b24258cc-e724-4ca1-b64e-c8f91400e031",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tokenized, lemmatized, no bad words'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/LyrAIX/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/PycharmProjects/LyrAIX/venv/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/LyrAIX/venv/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'tokenized, lemmatized, no bad words'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m lyric_corpus_tokenized \u001B[38;5;241m=\u001B[39m \u001B[43mlyrics\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtokenized, lemmatized, no bad words\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m      2\u001B[0m lyrics\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Users/zhenyabudnyk/PycharmProjects/LyrAIX/Thesis/Research Questions/RQ1/prompts.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;66;03m# the stopwords and very frequent and infrequent words are not removed here\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/LyrAIX/venv/lib/python3.8/site-packages/pandas/core/frame.py:3804\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3802\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3804\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3806\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/PycharmProjects/LyrAIX/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'tokenized, lemmatized, no bad words'"
     ]
    }
   ],
   "source": [
    "lyric_corpus_tokenized = lyrics['tokenized, lemmatized, no bad words'].tolist()\n",
    "lyrics.to_csv('/Users/zhenyabudnyk/PycharmProjects/LyrAIX/Thesis/Research Questions/RQ1/prompts.csv', index=False) # the stopwords and very frequent and infrequent words are not removed here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0 Valence Arousal Dominance    Part  \\\n0               0             0           0    High     Low    Medium  Chorus   \n1               1             1           1    High  Medium       Low  Bridge   \n2               2             2           2    High  Medium      High  Chorus   \n3               3             3           3  Medium     Low      High  Bridge   \n4               4             4           4  Medium    High    Medium  Chorus   \n..            ...           ...         ...     ...     ...       ...     ...   \n295           295           295         295    High    High       Low   Verse   \n296           296           296         296    High     Low      High   Verse   \n297           297           297         297     Low    High    Medium   Verse   \n298           298           298         298  Medium  Medium       Low   Verse   \n299           299           299         299    High    High      High   Verse   \n\n                          Artist                   Topic      Explicitness  \\\n0                     Sofya Wang  life and relationships            Normal   \n1                    Chiddy Bang  life and relationships            Normal   \n2                        Shwayze  life and relationships            Normal   \n3                   Dove Cameron                 general            Normal   \n4                         Weezer                 general            Normal   \n..                           ...                     ...               ...   \n295             The Irish Rovers                 general            Normal   \n296  Genius English Translations  life and relationships  Explicit content   \n297           Tiana Major9 & SiR                 general            Normal   \n298                  Spacey Jane    religion and society  Explicit content   \n299                   Chief Keef  life and relationships            Normal   \n\n                                                Scheme  \\\n0                                      0-0-0-1-0-0-1-1   \n1                                      0-0-1-2-3-4-5-6   \n2                                        0-1-2-0-3-3-4   \n3                                          0-1-2-1-1-1   \n4                                                    0   \n..                                                 ...   \n295  0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18...   \n296                                            0-0-0-0   \n297                                            0-1-2-1   \n298                                            0-1-2-3   \n299                                      0-1-1-2-2-1-3   \n\n                                           Instruction  \\\n0    Generate a Chorus of song lyrics in the style ...   \n1    Generate a Bridge of song lyrics in the style ...   \n2    Generate a Chorus of song lyrics in the style ...   \n3    Generate a Bridge of song lyrics in the style ...   \n4    Generate a Chorus of song lyrics in the style ...   \n..                                                 ...   \n295  Generate a Verse of song lyrics in the style o...   \n296  Generate a Verse of song lyrics in the style o...   \n297  Generate a Verse of song lyrics in the style o...   \n298  Generate a Verse of song lyrics in the style o...   \n299  Generate a Verse of song lyrics in the style o...   \n\n                                               results predicted explicitness  \\\n0    We're lying, we're lying in the shadows\\nI'm f...                 Normal   \n1    You don't wanna party\\nWhy you tryna party\\nI ...                 Normal   \n2    And if you run from me, baby, run from me\\nYou...                 Normal   \n3    Swing on by, all you can hear is me\\nLet's get...                 Normal   \n4            Singing like a symphony in a restaurant\\n                 Normal   \n..                                                 ...                    ...   \n295  Down to the wire\\nI'm down to the wire\\nI'm do...                 Normal   \n296  Well, I want to taste my eyes\\nI wanna see the...                 Normal   \n297  It's a big world, but I gotta do my thing\\nThe...                 Normal   \n298  Him to me a mwah a cryd for the people that kn...                 Normal   \n299  I been going every day, all the day\\nGot a lot...                 Normal   \n\n                                   predicted scheme  \\\n0                               0-1-2-3-4-5-6-7-8-9   \n1                                   0-1-2-3-4-2-4-5   \n2                                     0-1-2-3-4-5-4   \n3                                       0-1-2-3-4-5   \n4                                                 0   \n..                                              ...   \n295  0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18   \n296                                         0-0-1-2   \n297                                         0-1-2-3   \n298                                         0-0-0-0   \n299                                   0-1-2-3-4-5-3   \n\n                                            lemmatized  \\\n0    ['lying', 'lying', 'the', 'shadow', 'flying', ...   \n1    ['you', 'don', 'wanna', 'party', 'why', 'you',...   \n2    ['and', 'you', 'run', 'from', 'baby', 'run', '...   \n3    ['swing', 'all', 'you', 'can', 'hear', 'let', ...   \n4        ['singing', 'like', 'symphony', 'restaurant']   \n..                                                 ...   \n295  ['down', 'the', 'wire', 'down', 'the', 'wire',...   \n296  ['well', 'want', 'taste', 'eye', 'wanna', 'see...   \n297  ['big', 'world', 'but', 'gotta', 'thing', 'the...   \n298  ['him', 'mwah', 'cryd', 'for', 'the', 'people'...   \n299  ['been', 'going', 'every', 'day', 'all', 'the'...   \n\n                   tokenized, lemmatized, no bad words  \n0    [lying, lying, shadow, flying, flying, sky, st...  \n1    [wanna, party, tryna, party, even, gotta, say,...  \n2    [run, baby, run, could, live, good, life, run,...  \n3    [swing, hear, let, get, party, started, back, ...  \n4                [singing, like, symphony, restaurant]  \n..                                                 ...  \n295  [wire, wire, wire, wire, wire, wire, wire, wir...  \n296  [well, want, taste, eye, wanna, see, tearfully...  \n297  [big, world, gotta, thing, see, lot, energy, g...  \n298  [mwah, cryd, people, know, world, world, world...  \n299  [going, every, day, day, got, lot, problem, go...  \n\n[300 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.2</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>Valence</th>\n      <th>Arousal</th>\n      <th>Dominance</th>\n      <th>Part</th>\n      <th>Artist</th>\n      <th>Topic</th>\n      <th>Explicitness</th>\n      <th>Scheme</th>\n      <th>Instruction</th>\n      <th>results</th>\n      <th>predicted explicitness</th>\n      <th>predicted scheme</th>\n      <th>lemmatized</th>\n      <th>tokenized, lemmatized, no bad words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Medium</td>\n      <td>Chorus</td>\n      <td>Sofya Wang</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-0-0-1-0-0-1-1</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>We're lying, we're lying in the shadows\\nI'm f...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9</td>\n      <td>['lying', 'lying', 'the', 'shadow', 'flying', ...</td>\n      <td>[lying, lying, shadow, flying, flying, sky, st...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Bridge</td>\n      <td>Chiddy Bang</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-0-1-2-3-4-5-6</td>\n      <td>Generate a Bridge of song lyrics in the style ...</td>\n      <td>You don't wanna party\\nWhy you tryna party\\nI ...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-2-4-5</td>\n      <td>['you', 'don', 'wanna', 'party', 'why', 'you',...</td>\n      <td>[wanna, party, tryna, party, even, gotta, say,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>Chorus</td>\n      <td>Shwayze</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-1-2-0-3-3-4</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>And if you run from me, baby, run from me\\nYou...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-4</td>\n      <td>['and', 'you', 'run', 'from', 'baby', 'run', '...</td>\n      <td>[run, baby, run, could, live, good, life, run,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Bridge</td>\n      <td>Dove Cameron</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-1-1-1</td>\n      <td>Generate a Bridge of song lyrics in the style ...</td>\n      <td>Swing on by, all you can hear is me\\nLet's get...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5</td>\n      <td>['swing', 'all', 'you', 'can', 'hear', 'let', ...</td>\n      <td>[swing, hear, let, get, party, started, back, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Chorus</td>\n      <td>Weezer</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>Singing like a symphony in a restaurant\\n</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>['singing', 'like', 'symphony', 'restaurant']</td>\n      <td>[singing, like, symphony, restaurant]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>295</td>\n      <td>295</td>\n      <td>295</td>\n      <td>High</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Verse</td>\n      <td>The Irish Rovers</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18...</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Down to the wire\\nI'm down to the wire\\nI'm do...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18</td>\n      <td>['down', 'the', 'wire', 'down', 'the', 'wire',...</td>\n      <td>[wire, wire, wire, wire, wire, wire, wire, wir...</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>296</td>\n      <td>296</td>\n      <td>296</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Verse</td>\n      <td>Genius English Translations</td>\n      <td>life and relationships</td>\n      <td>Explicit content</td>\n      <td>0-0-0-0</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Well, I want to taste my eyes\\nI wanna see the...</td>\n      <td>Normal</td>\n      <td>0-0-1-2</td>\n      <td>['well', 'want', 'taste', 'eye', 'wanna', 'see...</td>\n      <td>[well, want, taste, eye, wanna, see, tearfully...</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>297</td>\n      <td>297</td>\n      <td>297</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Verse</td>\n      <td>Tiana Major9 &amp; SiR</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-1</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>It's a big world, but I gotta do my thing\\nThe...</td>\n      <td>Normal</td>\n      <td>0-1-2-3</td>\n      <td>['big', 'world', 'but', 'gotta', 'thing', 'the...</td>\n      <td>[big, world, gotta, thing, see, lot, energy, g...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>298</td>\n      <td>298</td>\n      <td>298</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Verse</td>\n      <td>Spacey Jane</td>\n      <td>religion and society</td>\n      <td>Explicit content</td>\n      <td>0-1-2-3</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Him to me a mwah a cryd for the people that kn...</td>\n      <td>Normal</td>\n      <td>0-0-0-0</td>\n      <td>['him', 'mwah', 'cryd', 'for', 'the', 'people'...</td>\n      <td>[mwah, cryd, people, know, world, world, world...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>299</td>\n      <td>299</td>\n      <td>299</td>\n      <td>High</td>\n      <td>High</td>\n      <td>High</td>\n      <td>Verse</td>\n      <td>Chief Keef</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-1-1-2-2-1-3</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>I been going every day, all the day\\nGot a lot...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-3</td>\n      <td>['been', 'going', 'every', 'day', 'all', 'the'...</td>\n      <td>[going, every, day, day, got, lot, problem, go...</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "lyrics.to_csv('/Users/zhenyabudnyk/PycharmProjects/LyrAIX/Thesis/Research Questions/RQ1/prompts.csv', index=False) # the stopwords and very frequent and infrequent words are not removed here\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa218a6d-9f93-4cd8-9514-b55c1964b638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing to the list: 100%|██████████| 2797631/2797631 [01:07<00:00, 41462.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['produced', 'irv', 'gotti', 'intro', 'hah', 'roc', 'fella', 'invite', 'somethin', 'epic', 'know', 'well', 'hustle', 'sense', 'hopelessness', 'sort', 'desperation', 'desperation', 'become', 'addicted', 'sort', 'like', 'fiend', 'accustomed', 'servin', 'feel', 'nothin', 'lose', 'offer', 'well', 'offer', 'life', 'right', 'bring', 'table', 'verse', 'watchin', 'every', 'watchin', 'closely', 'butter', 'bread', 'wanna', 'toast', 'keep', 'head', 'supposed', 'get', 'sidetracked', 'clapped', 'close', 'foot', 'sleep', 'tired', 'feel', 'wired', 'like', 'codeine', 'day', 'brother', 'gotta', 'admire', 'four', 'fiend', 'away', 'pain', 'wish', 'quick', 'see', 'sellin', 'caine', 'til', 'brain', 'fried', 'fricassee', 'lie', 'time', 'never', 'bothered', 'bar', 'gettin', 'properly', 'squad', 'lack', 'respect', 'authority', 'laughin', 'hard', 'happy', 'escapin', 'poverty', 'however', 'brief', 'know', 'game', 'got', 'valley', 'peak', 'expectation', 'dip', 'precipitation', 'stack', 'chip', 'hardly', 'youth', 'used', 'soon', 'see', 'mill', 'big', 'willie', 'game', 'ha', 'grown', 'prefer', 'call', 'william', 'illin', 'revenue', 'rayful', 'edmond', 'like', 'channel', 'news', 'round', 'seven', 'jewel', 'head', 'dead', 'mic', 'forgettin', 'ever', 'knew', 'convenient', 'amnesia', 'suggest', 'call', 'lawyer', 'know', 'procedure', 'lock', 'body', 'trap', 'mind', 'easily', 'explain', 'adapt', 'crime', 'rather', 'die', 'enormous', 'live', 'dormant', 'live', 'main', 'event', 'bet', 'trip', 'maui', 'presidential', 'suite', 'residential', 'weekend', 'confidentially', 'speakin', 'code', 'since', 'sense', 'peekin', 'nsx', 'rental', 'fooled', 'game', 'mental', 'town', 'dog', 'tryin', 'get', 'viva', 'la', 'vega', 'see', 'later', 'table', 'meet', 'one', 'start', 'way', 'fraud', 'present', 'gamblin', 'pleasant', 'time', 'sippin', 'margarita', 'chorus', 'geyeahhh', 'live', 'live', 'verse', 'mind', 'infested', 'sick', 'thought', 'circle', 'like', 'lexus', 'driven', 'wrong', 'sure', 'hurt', 'dual', 'level', 'like', 'duplex', 'unity', 'crew', 'commit', 'atrocity', 'like', 'got', 'immunity', 'guessed', 'manifest', 'tangible', 'good', 'platinum', 'rolex', 'lease', 'buy', 'whole', 'car', 'confederation', 'dead', 'nation', 'explode', 'detonation', 'overload', 'mind', 'said', 'patient', 'boil', 'steam', 'come', 'fiend', 'gotta', 'even', 'righteous', 'mind', 'true', 'street', 'school', 'spend', 'money', 'foolish', 'bond', 'jeweler', 'watch', 'intruder', 'stepped', 'another', 'level', 'meditated', 'like', 'buddhist', 'recruited', 'lieutenant', 'ludicrous', 'dream', 'gettin', 'cream', 'let', 'get', 'tedious', 'keep', 'one', 'eye', 'open', 'like', 'cbs', 'see', 'stressed', 'right', 'chorus', 'live', 'live', 'live', 'live']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lyrics_corpus_tokenized = list()\n",
    "# for song in tqdm(lyrics['no profanities and no stop words'], desc=\"writing to the list\"):\n",
    "#     lyrics_corpus_tokenized.append(song.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n",
    "# print(type(lyrics_corpus_tokenized[0]))\n",
    "# print(lyrics_corpus_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0 Valence Arousal Dominance    Part  \\\n0               0             0           0    High     Low    Medium  Chorus   \n1               1             1           1    High  Medium       Low  Bridge   \n2               2             2           2    High  Medium      High  Chorus   \n3               3             3           3  Medium     Low      High  Bridge   \n4               4             4           4  Medium    High    Medium  Chorus   \n..            ...           ...         ...     ...     ...       ...     ...   \n295           295           295         295    High    High       Low   Verse   \n296           296           296         296    High     Low      High   Verse   \n297           297           297         297     Low    High    Medium   Verse   \n298           298           298         298  Medium  Medium       Low   Verse   \n299           299           299         299    High    High      High   Verse   \n\n                          Artist                   Topic      Explicitness  \\\n0                     Sofya Wang  life and relationships            Normal   \n1                    Chiddy Bang  life and relationships            Normal   \n2                        Shwayze  life and relationships            Normal   \n3                   Dove Cameron                 general            Normal   \n4                         Weezer                 general            Normal   \n..                           ...                     ...               ...   \n295             The Irish Rovers                 general            Normal   \n296  Genius English Translations  life and relationships  Explicit content   \n297           Tiana Major9 & SiR                 general            Normal   \n298                  Spacey Jane    religion and society  Explicit content   \n299                   Chief Keef  life and relationships            Normal   \n\n                                                Scheme  \\\n0                                      0-0-0-1-0-0-1-1   \n1                                      0-0-1-2-3-4-5-6   \n2                                        0-1-2-0-3-3-4   \n3                                          0-1-2-1-1-1   \n4                                                    0   \n..                                                 ...   \n295  0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18...   \n296                                            0-0-0-0   \n297                                            0-1-2-1   \n298                                            0-1-2-3   \n299                                      0-1-1-2-2-1-3   \n\n                                           Instruction  \\\n0    Generate a Chorus of song lyrics in the style ...   \n1    Generate a Bridge of song lyrics in the style ...   \n2    Generate a Chorus of song lyrics in the style ...   \n3    Generate a Bridge of song lyrics in the style ...   \n4    Generate a Chorus of song lyrics in the style ...   \n..                                                 ...   \n295  Generate a Verse of song lyrics in the style o...   \n296  Generate a Verse of song lyrics in the style o...   \n297  Generate a Verse of song lyrics in the style o...   \n298  Generate a Verse of song lyrics in the style o...   \n299  Generate a Verse of song lyrics in the style o...   \n\n                                               results predicted explicitness  \\\n0    We're lying, we're lying in the shadows\\nI'm f...                 Normal   \n1    You don't wanna party\\nWhy you tryna party\\nI ...                 Normal   \n2    And if you run from me, baby, run from me\\nYou...                 Normal   \n3    Swing on by, all you can hear is me\\nLet's get...                 Normal   \n4            Singing like a symphony in a restaurant\\n                 Normal   \n..                                                 ...                    ...   \n295  Down to the wire\\nI'm down to the wire\\nI'm do...                 Normal   \n296  Well, I want to taste my eyes\\nI wanna see the...                 Normal   \n297  It's a big world, but I gotta do my thing\\nThe...                 Normal   \n298  Him to me a mwah a cryd for the people that kn...                 Normal   \n299  I been going every day, all the day\\nGot a lot...                 Normal   \n\n                                   predicted scheme  \\\n0                               0-1-2-3-4-5-6-7-8-9   \n1                                   0-1-2-3-4-2-4-5   \n2                                     0-1-2-3-4-5-4   \n3                                       0-1-2-3-4-5   \n4                                                 0   \n..                                              ...   \n295  0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18   \n296                                         0-0-1-2   \n297                                         0-1-2-3   \n298                                         0-0-0-0   \n299                                   0-1-2-3-4-5-3   \n\n                                            lemmatized  \n0    ['lying', 'lying', 'the', 'shadow', 'flying', ...  \n1    ['you', 'don', 'wanna', 'party', 'why', 'you',...  \n2    ['and', 'you', 'run', 'from', 'baby', 'run', '...  \n3    ['swing', 'all', 'you', 'can', 'hear', 'let', ...  \n4        ['singing', 'like', 'symphony', 'restaurant']  \n..                                                 ...  \n295  ['down', 'the', 'wire', 'down', 'the', 'wire',...  \n296  ['well', 'want', 'taste', 'eye', 'wanna', 'see...  \n297  ['big', 'world', 'but', 'gotta', 'thing', 'the...  \n298  ['him', 'mwah', 'cryd', 'for', 'the', 'people'...  \n299  ['been', 'going', 'every', 'day', 'all', 'the'...  \n\n[300 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.2</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>Valence</th>\n      <th>Arousal</th>\n      <th>Dominance</th>\n      <th>Part</th>\n      <th>Artist</th>\n      <th>Topic</th>\n      <th>Explicitness</th>\n      <th>Scheme</th>\n      <th>Instruction</th>\n      <th>results</th>\n      <th>predicted explicitness</th>\n      <th>predicted scheme</th>\n      <th>lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Medium</td>\n      <td>Chorus</td>\n      <td>Sofya Wang</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-0-0-1-0-0-1-1</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>We're lying, we're lying in the shadows\\nI'm f...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9</td>\n      <td>['lying', 'lying', 'the', 'shadow', 'flying', ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Bridge</td>\n      <td>Chiddy Bang</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-0-1-2-3-4-5-6</td>\n      <td>Generate a Bridge of song lyrics in the style ...</td>\n      <td>You don't wanna party\\nWhy you tryna party\\nI ...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-2-4-5</td>\n      <td>['you', 'don', 'wanna', 'party', 'why', 'you',...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>Chorus</td>\n      <td>Shwayze</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-1-2-0-3-3-4</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>And if you run from me, baby, run from me\\nYou...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-4</td>\n      <td>['and', 'you', 'run', 'from', 'baby', 'run', '...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Bridge</td>\n      <td>Dove Cameron</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-1-1-1</td>\n      <td>Generate a Bridge of song lyrics in the style ...</td>\n      <td>Swing on by, all you can hear is me\\nLet's get...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5</td>\n      <td>['swing', 'all', 'you', 'can', 'hear', 'let', ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>Medium</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Chorus</td>\n      <td>Weezer</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>Generate a Chorus of song lyrics in the style ...</td>\n      <td>Singing like a symphony in a restaurant\\n</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>['singing', 'like', 'symphony', 'restaurant']</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>295</td>\n      <td>295</td>\n      <td>295</td>\n      <td>High</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Verse</td>\n      <td>The Irish Rovers</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18...</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Down to the wire\\nI'm down to the wire\\nI'm do...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18</td>\n      <td>['down', 'the', 'wire', 'down', 'the', 'wire',...</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>296</td>\n      <td>296</td>\n      <td>296</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Verse</td>\n      <td>Genius English Translations</td>\n      <td>life and relationships</td>\n      <td>Explicit content</td>\n      <td>0-0-0-0</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Well, I want to taste my eyes\\nI wanna see the...</td>\n      <td>Normal</td>\n      <td>0-0-1-2</td>\n      <td>['well', 'want', 'taste', 'eye', 'wanna', 'see...</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>297</td>\n      <td>297</td>\n      <td>297</td>\n      <td>Low</td>\n      <td>High</td>\n      <td>Medium</td>\n      <td>Verse</td>\n      <td>Tiana Major9 &amp; SiR</td>\n      <td>general</td>\n      <td>Normal</td>\n      <td>0-1-2-1</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>It's a big world, but I gotta do my thing\\nThe...</td>\n      <td>Normal</td>\n      <td>0-1-2-3</td>\n      <td>['big', 'world', 'but', 'gotta', 'thing', 'the...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>298</td>\n      <td>298</td>\n      <td>298</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Low</td>\n      <td>Verse</td>\n      <td>Spacey Jane</td>\n      <td>religion and society</td>\n      <td>Explicit content</td>\n      <td>0-1-2-3</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>Him to me a mwah a cryd for the people that kn...</td>\n      <td>Normal</td>\n      <td>0-0-0-0</td>\n      <td>['him', 'mwah', 'cryd', 'for', 'the', 'people'...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>299</td>\n      <td>299</td>\n      <td>299</td>\n      <td>High</td>\n      <td>High</td>\n      <td>High</td>\n      <td>Verse</td>\n      <td>Chief Keef</td>\n      <td>life and relationships</td>\n      <td>Normal</td>\n      <td>0-1-1-2-2-1-3</td>\n      <td>Generate a Verse of song lyrics in the style o...</td>\n      <td>I been going every day, all the day\\nGot a lot...</td>\n      <td>Normal</td>\n      <td>0-1-2-3-4-5-3</td>\n      <td>['been', 'going', 'every', 'day', 'all', 'the'...</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f36c1a0-ac68-4db9-9f0b-907b3ad08195",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_remove = {'verse', 'chorus', 'hook', 'bridge', 'intro', 'outro', 'pre-chorus', 'pre-hook', 'get', 'got'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb6b415-cc65-4223-bccc-c8e29b4d174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "removing: 100%|██████████| 5334078/5334078 [00:51<00:00, 104157.25it/s]\n"
     ]
    }
   ],
   "source": [
    "lyric_corpus_tokenized = [\n",
    "    [token for token in song if token not in words_to_remove]\n",
    "    for song in tqdm(lyric_corpus_tokenized, desc=\"removing\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "516b50ab-d25b-42e2-8582-c430c046d54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/jovyan/.local/lib/python3.8/site-packages (4.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/jovyan/.local/lib/python3.8/site-packages (from gensim) (6.3.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a28ee86-717b-4022-baea-cd7b7e8aa99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyrics_corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3b0f9d0-f953-4228-af20-d63fa6eb9dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dictionary: 100%|██████████| 5334078/5334078 [03:38<00:00, 24416.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Assuming you have a big list called 'big_list'\n",
    "  # Number of items to choose\n",
    "\n",
    "# Randomly select 20,000 items from the big list\n",
    "# lyric_corpus_tokenized = lyric_corpus_tokenized.tolist()\n",
    "\n",
    "tqdm_corpus = tqdm(lyric_corpus_tokenized, desc=\"Creating dictionary\")\n",
    "dictionary = Dictionary(tqdm_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82c95a1d-fee6-469b-a320-162a61c33e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=100, no_above=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bb441aa-637b-4b28-af57-f655a6404514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Gensim Corpus: 100%|██████████| 5334078/5334078 [02:21<00:00, 37624.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import MmCorpus\n",
    "gensim_corpus = []\n",
    "with tqdm(total=len(lyric_corpus_tokenized), desc=\"Creating Gensim Corpus\") as pbar:\n",
    "    for song in lyric_corpus_tokenized:\n",
    "        doc = dictionary.doc2bow(song)\n",
    "        gensim_corpus.append(doc)\n",
    "        pbar.update(1)\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "226d9d2e-6672-48ee-a012-e8e0b6245086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accustomed\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a27d1d9d-4570-4382-8859-93746a4d8ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5334078\n"
     ]
    }
   ],
   "source": [
    "print(len(gensim_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a217eeb2-b83e-452e-a15b-b926ce38d8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1313.68 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "start_time = time.time()\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "num_topics = 6\n",
    "sample_size = 2000000\n",
    "\n",
    "\n",
    "gensim2 = random.sample(gensim_corpus, sample_size)\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=gensim_corpus[],\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Training time: {:.2f} seconds\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8de4d96-c392-42b9-8493-88efa8281482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting topics:   0%|          | 837/2797631 [00:00<18:53, 2468.12it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 16583 is out of bounds for axis 1 with size 16583",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(gensim_corpus), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPredicting topics\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m song \u001B[38;5;129;01min\u001B[39;00m gensim_corpus:\n\u001B[0;32m----> 4\u001B[0m         topic_dist \u001B[38;5;241m=\u001B[39m \u001B[43mlda_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_document_topics\u001B[49m\u001B[43m(\u001B[49m\u001B[43msong\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m         predicted_topics\u001B[38;5;241m.\u001B[39mappend(topic_dist)\n\u001B[1;32m      6\u001B[0m         pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/gensim/models/ldamodel.py:1354\u001B[0m, in \u001B[0;36mLdaModel.get_document_topics\u001B[0;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001B[0m\n\u001B[1;32m   1347\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\n\u001B[1;32m   1348\u001B[0m         per_word_topics\u001B[38;5;241m=\u001B[39mper_word_topics,\n\u001B[1;32m   1349\u001B[0m         minimum_probability\u001B[38;5;241m=\u001B[39mminimum_probability,\n\u001B[1;32m   1350\u001B[0m         minimum_phi_value\u001B[38;5;241m=\u001B[39mminimum_phi_value\n\u001B[1;32m   1351\u001B[0m     )\n\u001B[1;32m   1352\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply(corpus, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 1354\u001B[0m gamma, phis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minference\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbow\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollect_sstats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mper_word_topics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1355\u001B[0m topic_dist \u001B[38;5;241m=\u001B[39m gamma[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;28msum\u001B[39m(gamma[\u001B[38;5;241m0\u001B[39m])  \u001B[38;5;66;03m# normalize distribution\u001B[39;00m\n\u001B[1;32m   1357\u001B[0m document_topics \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   1358\u001B[0m     (topicid, topicvalue) \u001B[38;5;28;01mfor\u001B[39;00m topicid, topicvalue \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(topic_dist)\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m topicvalue \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m minimum_probability\n\u001B[1;32m   1360\u001B[0m ]\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/gensim/models/ldamodel.py:706\u001B[0m, in \u001B[0;36mLdaModel.inference\u001B[0;34m(self, chunk, collect_sstats)\u001B[0m\n\u001B[1;32m    704\u001B[0m Elogthetad \u001B[38;5;241m=\u001B[39m Elogtheta[d, :]\n\u001B[1;32m    705\u001B[0m expElogthetad \u001B[38;5;241m=\u001B[39m expElogtheta[d, :]\n\u001B[0;32m--> 706\u001B[0m expElogbetad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpElogbeta\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mids\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[38;5;66;03m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_kw.\u001B[39;00m\n\u001B[1;32m    709\u001B[0m \u001B[38;5;66;03m# phinorm is the normalizer.\u001B[39;00m\n\u001B[1;32m    710\u001B[0m \u001B[38;5;66;03m# TODO treat zeros explicitly, instead of adding epsilon?\u001B[39;00m\n\u001B[1;32m    711\u001B[0m phinorm \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(expElogthetad, expElogbetad) \u001B[38;5;241m+\u001B[39m epsilon\n",
      "\u001B[0;31mIndexError\u001B[0m: index 16583 is out of bounds for axis 1 with size 16583"
     ]
    }
   ],
   "source": [
    "predicted_topics = []\n",
    "with tqdm(total=len(gensim_corpus), desc=\"Predicting topics\") as pbar:\n",
    "    for song in gensim_corpus:\n",
    "        topic_dist = lda_model.get_document_topics(song)\n",
    "        predicted_topics.append(topic_dist)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c089c57-3176-4d2e-8d61-fec55b59572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save(\"lda_model400\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "71a4337f-dae0-435b-900f-c76f187a9958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyLDAvis in /home/jovyan/.local/lib/python3.8/site-packages (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.23.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.10.1)\n",
      "Requirement already satisfied: pandas>=1.3.4 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (3.1.2)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (2.8.4)\n",
      "Requirement already satisfied: funcy in /home/jovyan/.local/lib/python3.8/site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.1.3)\n",
      "Requirement already satisfied: gensim in /home/jovyan/.local/lib/python3.8/site-packages (from pyLDAvis) (4.3.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (67.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.4->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.4->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.4->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/jovyan/.local/lib/python3.8/site-packages (from gensim->pyLDAvis) (6.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->pyLDAvis) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jovyan/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.4->pyLDAvis) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38834f87-8d74-4478-bdd6-cec360e68f48",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyLDAvis\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyLDAvis\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgensim_models\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgensimvis\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m vis_data \u001B[38;5;241m=\u001B[39m \u001B[43mgensimvis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlda_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgensim_corpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdictionary\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m pyLDAvis\u001B[38;5;241m.\u001B[39mdisplay(vis_data)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyLDAvis/gensim_models.py:123\u001B[0m, in \u001B[0;36mprepare\u001B[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001B[39;00m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;124;03mthe data structures needed for the visualization.\u001B[39;00m\n\u001B[1;32m     80\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;124;03mSee `pyLDAvis.prepare` for **kwargs.\u001B[39;00m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    122\u001B[0m opts \u001B[38;5;241m=\u001B[39m fp\u001B[38;5;241m.\u001B[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001B[0;32m--> 123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpyLDAvis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mopts\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyLDAvis/_prepare.py:432\u001B[0m, in \u001B[0;36mprepare\u001B[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;66;03m# Quick fix for red bar width bug.  We calculate the\u001B[39;00m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;66;03m# term frequencies internally, using the topic term distributions and the\u001B[39;00m\n\u001B[1;32m    428\u001B[0m \u001B[38;5;66;03m# topic frequencies, rather than using the user-supplied term frequencies.\u001B[39;00m\n\u001B[1;32m    429\u001B[0m \u001B[38;5;66;03m# For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41\u001B[39;00m\n\u001B[1;32m    430\u001B[0m term_frequency \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(term_topic_freq, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 432\u001B[0m topic_info \u001B[38;5;241m=\u001B[39m \u001B[43m_topic_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopic_term_dists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopic_proportion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mterm_frequency\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mterm_topic_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mR\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    435\u001B[0m token_table \u001B[38;5;241m=\u001B[39m _token_table(topic_info, term_topic_freq, vocab, term_frequency, start_index)\n\u001B[1;32m    436\u001B[0m topic_coordinates \u001B[38;5;241m=\u001B[39m _topic_coordinates(mds, topic_term_dists, topic_proportion, start_index)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyLDAvis/_prepare.py:243\u001B[0m, in \u001B[0;36m_topic_info\u001B[0;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs, start_index)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;66;03m# Order the terms for the \"default\" view by decreasing saliency:\u001B[39;00m\n\u001B[1;32m    237\u001B[0m default_term_info \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msaliency\u001B[39m\u001B[38;5;124m'\u001B[39m: saliency,\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTerm\u001B[39m\u001B[38;5;124m'\u001B[39m: vocab,\n\u001B[1;32m    240\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFreq\u001B[39m\u001B[38;5;124m'\u001B[39m: term_frequency,\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTotal\u001B[39m\u001B[38;5;124m'\u001B[39m: term_frequency,\n\u001B[1;32m    242\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCategory\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDefault\u001B[39m\u001B[38;5;124m'\u001B[39m})\n\u001B[0;32m--> 243\u001B[0m default_term_info \u001B[38;5;241m=\u001B[39m \u001B[43mdefault_term_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43mby\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msaliency\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mascending\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead\u001B[49m\u001B[43m(\u001B[49m\u001B[43mR\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msaliency\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[38;5;66;03m# Rounding Freq and Total to integer values to match LDAvis code:\u001B[39;00m\n\u001B[1;32m    246\u001B[0m default_term_info[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFreq\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfloor(default_term_info[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFreq\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mTypeError\u001B[0m: drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "vis_data = gensimvis.prepare(lda_model, gensim_corpus, dictionary)\n",
    "pyLDAvis.display(vis_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "217ad4eb-52a7-4472-814b-708f2a294aac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vis_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m pyLDAvis\u001B[38;5;241m.\u001B[39msave_html(\u001B[43mvis_data\u001B[49m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./Lyrics_LDA_k_\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(num_topics) \u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.html\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'vis_data' is not defined"
     ]
    }
   ],
   "source": [
    "pyLDAvis.save_html(vis_data, './Lyrics_LDA_k_'+ str(num_topics) +'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f9783b6-5e75-4945-8bc5-c493fc71a4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001B[31mERROR: Ignored the following versions that require a different python version: 3.4.1 Requires-Python >=3.9\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[31mERROR: Could not find a version that satisfies the requirement pyLDAvis==3.4.1 (from versions: 1.0.0, 1.1.0, 1.2.0, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 2.0.0, 2.1.0, 2.1.1, 2.1.2, 3.0.0, 3.1.0, 3.2.0, 3.2.1, 3.2.2, 3.3.0, 3.3.1, 3.4.0)\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for pyLDAvis==3.4.1\u001B[0m\u001B[31m\n",
      "\u001B[0m3.4.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==1.5.3 in /home/jovyan/.local/lib/python3.8/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.3) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.3) (1.23.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/jovyan/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "#print(pyLDAvis.__version__)\n",
    "!pip install pyLDAvis==3.4.1\n",
    "print(pyLDAvis.__version__)\n",
    "!pip install pandas==1.5.3\n",
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01d25cf9-2bbf-40f6-9a94-0a6fc1a2f6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9e4814c-38c4-422b-8a2a-f3189a88531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c6b4fe4-1e55-4039-aa12-b2f98ceb2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora import MmCorpus\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "lda_model = LdaModel.load('lda_model400')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c182836-d41b-4f35-a573-5fc46a0d6385",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyLDAvis\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyLDAvis\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgensim_models\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgensimvis\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m vis_data \u001B[38;5;241m=\u001B[39m \u001B[43mgensimvis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlda_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgensim_corpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdictionary\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m pyLDAvis\u001B[38;5;241m.\u001B[39mdisplay(vis_data)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#pyLDAvis.save_html(vis_data, './Lyrics_LDA_k_'+ str(num_topics) +'.html')\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyLDAvis/gensim_models.py:122\u001B[0m, in \u001B[0;36mprepare\u001B[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprepare\u001B[39m(topic_model, corpus, dictionary, doc_topic_dist\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     78\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001B[39;00m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;124;03m    the data structures needed for the visualization.\u001B[39;00m\n\u001B[1;32m     80\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;124;03m    See `pyLDAvis.prepare` for **kwargs.\u001B[39;00m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     opts \u001B[38;5;241m=\u001B[39m fp\u001B[38;5;241m.\u001B[39mmerge(\u001B[43m_extract_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopic_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdictionary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdoc_topic_dist\u001B[49m\u001B[43m)\u001B[49m, kwargs)\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pyLDAvis\u001B[38;5;241m.\u001B[39mprepare(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mopts)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyLDAvis/gensim_models.py:17\u001B[0m, in \u001B[0;36m_extract_data\u001B[0;34m(topic_model, corpus, dictionary, doc_topic_dists)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m gensim\u001B[38;5;241m.\u001B[39mmatutils\u001B[38;5;241m.\u001B[39mismatrix(corpus):\n\u001B[0;32m---> 17\u001B[0m     corpus_csc \u001B[38;5;241m=\u001B[39m \u001B[43mgensim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorpus2csc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_terms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdictionary\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     19\u001B[0m     corpus_csc \u001B[38;5;241m=\u001B[39m corpus\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/gensim/matutils.py:152\u001B[0m, in \u001B[0;36mcorpus2csc\u001B[0;34m(corpus, num_terms, dtype, num_docs, num_nnz, printprogress)\u001B[0m\n\u001B[1;32m    149\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPROGRESS: at document #\u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, docno)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;66;03m# zip(*doc) transforms doc to (token_indices, token_counts]\u001B[39;00m\n\u001B[0;32m--> 152\u001B[0m doc_indices, doc_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m doc \u001B[38;5;28;01melse\u001B[39;00m ([], [])\n\u001B[1;32m    153\u001B[0m indices\u001B[38;5;241m.\u001B[39mextend(doc_indices)\n\u001B[1;32m    154\u001B[0m data\u001B[38;5;241m.\u001B[39mextend(doc_data)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "vis_data = gensimvis.prepare(lda_model, gensim_corpus, dictionary)\n",
    "pyLDAvis.display(vis_data)\n",
    "#pyLDAvis.save_html(vis_data, './Lyrics_LDA_k_'+ str(num_topics) +'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "856d62b0-c8be-4fd8-939a-59ba1a5686ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = pd.read_csv('song_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72c0ff7e-8dc9-456e-abef-a464aab55749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1708442  life and relationships\n",
      "1980937  money and authority\n",
      "1266192  general\n",
      "378507  religion and society\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = lyrics['topic'].value_counts()['life and relationships']\n",
    "print(count, \" life and relationships\")\n",
    "count = lyrics['topic'].value_counts()['money and authority']\n",
    "print(count, \" money and authority\")\n",
    "count = lyrics['topic'].value_counts()['general']\n",
    "print(count, \" general\")\n",
    "count = lyrics['topic'].value_counts()['religion and society']\n",
    "print(count, \" religion and society\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d981f-e151-4069-b403-2f2b31a8773e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
